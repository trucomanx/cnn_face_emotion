{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dcc51ca",
   "metadata": {},
   "source": [
    "    !wget https://www.dropbox.com/s/23tutsg2m9o78bp/fer2013.zip\n",
    "    !unzip -n fer2013.zip\n",
    "    !rm fer2013.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985bcc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_default_json_conf_file='cnn_face_emotion_training_default.json';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9197c618",
   "metadata": {},
   "source": [
    "# Bibliotecas externas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cce09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c28ba2",
   "metadata": {},
   "source": [
    "# Biblioteca local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f55909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../library');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0c9a8",
   "metadata": {},
   "source": [
    "# Uso de GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "436cdeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead847f2",
   "metadata": {},
   "source": [
    "# Load default DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e5481",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load json conf json file\n",
    "fd = open(os.path.join('./',input_default_json_conf_file));\n",
    "DATA = json.load(fd);\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0f452-3278-49c0-9601-c8a443dbc32b",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83c3fa6-dbbb-4644-a12f-e497f971a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "\n",
    "## Seed for the random variables\n",
    "seed_number=0;\n",
    "\n",
    "## Dataset \n",
    "dataset_base_dir    = DATA['dataset_train_base_dir'];\n",
    "dataset_labels_file = DATA['dataset_train_labels_file'];\n",
    "\n",
    "dataset_base_test_dir    = DATA['dataset_test_base_dir'];\n",
    "dataset_labels_test_file = DATA['dataset_test_labels_file'];\n",
    "\n",
    "dataset_name        = DATA['dataset_name'];\n",
    "\n",
    "## Training hyperparameters\n",
    "EPOCAS     = DATA[\"epochs\"];\n",
    "BATCH_SIZE = DATA[\"batch_size\"];\n",
    "\n",
    "## Model of network\n",
    "## 'mobilenet_v3', 'efficientnet_b3', 'inception_v3', 'inception_resnet_v2', 'resnet_v2_50'\n",
    "model_type = DATA[\"model_type\"];\n",
    "\n",
    "## Output\n",
    "output_base_dir = DATA[\"output_base_dir\"];\n",
    "\n",
    "## fine tuning\n",
    "fine_tuning=DATA[\"finetuning\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f43c5",
   "metadata": {},
   "source": [
    "# Parametros de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ffd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for n in range(len(sys.argv)):\n",
    "    if sys.argv[n]=='--dataset-train-dir':\n",
    "        dataset_base_dir=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--dataset-train-file':\n",
    "        dataset_labels_file=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--dataset-test-dir':\n",
    "        dataset_base_test_dir=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--dataset-test-file':\n",
    "        dataset_labels_test_file=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--dataset-name':\n",
    "        dataset_name=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--model':\n",
    "        model_type=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--epochs':\n",
    "        EPOCAS=int(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--batch-size':\n",
    "        BATCH_SIZE=int(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--fine-tuning':\n",
    "        fine_tuning=sys.argv[n+1].lower()=='true';\n",
    "    elif sys.argv[n]=='--output-dir':\n",
    "        output_base_dir=sys.argv[n+1];\n",
    "        \n",
    "print('        dataset_base_dir:',dataset_base_dir)\n",
    "print('     dataset_labels_file:',dataset_labels_file)\n",
    "print('   dataset_base_test_dir:',dataset_base_test_dir)\n",
    "print('dataset_labels_test_file:',dataset_labels_test_file)\n",
    "print('            dataset_name:',dataset_name)\n",
    "print('              model_type:',model_type)\n",
    "print('                  EPOCAS:',EPOCAS)\n",
    "print('              BATCH_SIZE:',BATCH_SIZE)\n",
    "print('             fine_tuning:',fine_tuning)\n",
    "print('         output_base_dir:',output_base_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1dee5-778a-4fd9-80de-90620bb33128",
   "metadata": {},
   "source": [
    "# Set seed of random variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ddef12f-6604-4c71-9473-15f328e954dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "tf.keras.utils.set_random_seed(seed_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a59004-739e-4760-bd91-ee3808207e3e",
   "metadata": {},
   "source": [
    "# Loading data of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe0e9b-ee46-40d8-97c3-12a1efc0cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load filenames and labels\n",
    "train_val_data = pd.read_csv(os.path.join(dataset_base_dir,dataset_labels_file));\n",
    "print(train_val_data)\n",
    "\n",
    "# Setting labels\n",
    "Y = train_val_data[['label']];\n",
    "L=np.shape(Y)[0];\n",
    "\n",
    "# Load test filenames and labels\n",
    "test_data = pd.read_csv(os.path.join(dataset_base_test_dir,dataset_labels_test_file));\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da712f-5937-4965-9623-82c4ee139297",
   "metadata": {},
   "source": [
    "# Setting the cross-validation split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab2262-3467-4ee3-86a8-9eda4f5ff726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "\n",
    "training_data, validation_data = train_test_split(train_val_data, test_size=0.2,shuffle=True, stratify=Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67beeb38-1ad1-455d-8a71-5900a1e88163",
   "metadata": {},
   "source": [
    "# Data augmentation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e3e68f-50e7-4f8c-9cd6-ae3261e8f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "idg    = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range = 10,\n",
    "                            width_shift_range= 0.07,\n",
    "                            height_shift_range= 0.07,\n",
    "                            horizontal_flip=True,\n",
    "                            shear_range=1.25,\n",
    "                            zoom_range = [0.75, 1.25]\n",
    "                            )\n",
    "\n",
    "idg_val = ImageDataGenerator(rescale=1./255 )\n",
    "\n",
    "idg_test= ImageDataGenerator(rescale=1./255 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5189cf-b447-4b0a-b9f3-56f304d6fdde",
   "metadata": {},
   "source": [
    "# Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a786de7-43ac-4597-92eb-d9eee66f81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tuning:\n",
    "    output_dir = os.path.join(output_base_dir,dataset_name,'training_validation_holdout_fine_tuning',model_type);\n",
    "else:\n",
    "    output_dir = os.path.join(output_base_dir,dataset_name,'training_validation_holdout',model_type);\n",
    "\n",
    "os.makedirs(output_dir,exist_ok = True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf04e51-7a7b-4116-8e1e-04e5f358c5dc",
   "metadata": {},
   "source": [
    "# Create new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d629ba9-d621-4905-a88f-a0730d6c1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib_model as mpp\n",
    "\n",
    "# CREATE NEW MODEL\n",
    "if   dataset_name=='fer2013':\n",
    "    model, target_size = mpp.create_model(file_of_weight='',model_type=model_type,nout=7,tuning_feature_extractor=False);\n",
    "elif dataset_name=='affectnet':\n",
    "    model, target_size = mpp.create_model(file_of_weight='',model_type=model_type,nout=8,tuning_feature_extractor=False);\n",
    "elif dataset_name=='mcfer_v1.0':\n",
    "    model, target_size = mpp.create_model(file_of_weight='',model_type=model_type,nout=7,tuning_feature_extractor=False);\n",
    "elif dataset_name=='ber2024-face':\n",
    "    model, target_size = mpp.create_model(file_of_weight='',model_type=model_type,nout=4,tuning_feature_extractor=False);\n",
    "else:\n",
    "    print('Error in the dataset name.');\n",
    "    exit();\n",
    "\n",
    "model.summary()\n",
    "\n",
    "mpp.save_model_parameters(model, os.path.join(output_dir,'parameters_stats.m'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59917a-4069-439f-9108-e5b139498b01",
   "metadata": {},
   "source": [
    "# Defining directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f2152-96da-447d-b437-84f11e12937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_generator = idg.flow_from_dataframe( training_data, \n",
    "                                                directory = dataset_base_dir,\n",
    "                                                target_size=target_size,\n",
    "                                                x_col = \"filename\", \n",
    "                                                y_col = \"label\",\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                shuffle = True);\n",
    "\n",
    "valid_data_generator  = idg_val.flow_from_dataframe(validation_data, \n",
    "                                                    directory = dataset_base_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    x_col = \"filename\", \n",
    "                                                    y_col = \"label\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    shuffle = True);\n",
    "\n",
    "test_data_generator  = idg_test.flow_from_dataframe(test_data, \n",
    "                                                    directory = dataset_base_test_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    x_col = \"filename\", \n",
    "                                                    y_col = \"label\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    shuffle = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1be572-b9c7-422c-9518-53735f9425c7",
   "metadata": {},
   "source": [
    "# Train and validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd68b8-e1aa-4ef4-af04-e05781f309ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#STEPS_BY_EPOCHS=len(train_data_generator);\n",
    "\n",
    "# COMPILE NEW MODEL\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "# CREATE CALLBACKS\n",
    "best_model_file=os.path.join(output_dir,'model.h5');\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=best_model_file, \n",
    "                                                save_weights_only=True,\n",
    "                                                monitor='val_loss', \n",
    "                                                save_best_only=True, \n",
    "                                                verbose=1);\n",
    "\n",
    "log_dir = os.path.join(output_dir,\"logs\",\"fit\", 'coarse_tunning-'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"));\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# There can be other callbacks, but just showing one because it involves the model name\n",
    "# This saves the best model\n",
    "# FIT THE MODEL\n",
    "history = model.fit(train_data_generator,\n",
    "                    #steps_per_epoch=STEPS_BY_EPOCHS,\n",
    "                    epochs=EPOCAS,\n",
    "                    validation_data=valid_data_generator,\n",
    "                    callbacks=[checkpoint,tensorboard_callback],\n",
    "                    verbose=1\n",
    "                   );\n",
    "\n",
    "\n",
    "mpp.save_model_history( history,\n",
    "                        os.path.join(output_dir,\"historical.csv\"),\n",
    "                        show=False,\n",
    "                        labels=['categorical_accuracy','loss']);\n",
    "\n",
    "\n",
    "if fine_tuning:\n",
    "    tf.keras.backend.clear_session();\n",
    "    #import torch\n",
    "    #torch.cuda.empty_cache();\n",
    "    del model\n",
    "    del history\n",
    "    \n",
    "    # CREATE NEW MODEL\n",
    "    if   dataset_name=='fer2013':\n",
    "        model, target_size = mpp.create_model(file_of_weight=best_model_file,model_type=model_type,nout=7,tuning_feature_extractor=True);\n",
    "    elif dataset_name=='affectnet':\n",
    "        model, target_size = mpp.create_model(file_of_weight=best_model_file,model_type=model_type,nout=8,tuning_feature_extractor=True);\n",
    "    elif dataset_name=='mcfer_v1.0':\n",
    "        model, target_size = mpp.create_model(file_of_weight=best_model_file,model_type=model_type,nout=7,tuning_feature_extractor=True);\n",
    "    elif dataset_name=='ber2024-face':\n",
    "        model, target_size = mpp.create_model(file_of_weight=best_model_file,model_type=model_type,nout=4,tuning_feature_extractor=True);\n",
    "    else:\n",
    "        print('Error in the dataset name.');\n",
    "        exit();\n",
    "\n",
    "    #necessary for these changes to take effect\n",
    "    model.compile(  loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['categorical_accuracy'])\n",
    "    \n",
    "    model.summary();\n",
    "    \n",
    "    log_dir = os.path.join(output_dir,\"logs\",\"fit\",'fine_tunning-'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"));\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    history = model.fit(train_data_generator,\n",
    "                        #steps_per_epoch=STEPS_BY_EPOCHS,\n",
    "                        epochs=EPOCAS,\n",
    "                        validation_data=valid_data_generator,\n",
    "                        callbacks=[checkpoint,tensorboard_callback],\n",
    "                        verbose=1\n",
    "                    );\n",
    "\n",
    "\n",
    "    mpp.save_model_history( history,\n",
    "                            os.path.join(output_dir,\"historical-fine_tuning.csv\"),\n",
    "                            show=False,\n",
    "                            labels=['categorical_accuracy','loss']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083be078-c76e-423a-a538-6e5c6c9cda8c",
   "metadata": {},
   "source": [
    "# Evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f6536-46f0-4c89-b98f-7cb5a4075cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD BEST MODEL to evaluate the performance of the model\n",
    "model.load_weights(best_model_file);\n",
    "data_results=dict();\n",
    "\n",
    "# Evaluate training\n",
    "results = model.evaluate(train_data_generator)\n",
    "results = dict(zip(model.metrics_names,results))\n",
    "print('training',results,\"\\n\\n\");\n",
    "for key,value in results.items():\n",
    "    data_results['train_'+key]=value;\n",
    "\n",
    "# Evaluate validation\n",
    "results = model.evaluate(valid_data_generator)\n",
    "results = dict(zip(model.metrics_names,results))\n",
    "print('validation',results,\"\\n\\n\");\n",
    "for key,value in results.items():\n",
    "    data_results['val_'+key]=value;\n",
    "\n",
    "# Evaluate testing\n",
    "results = model.evaluate(test_data_generator)\n",
    "results = dict(zip(model.metrics_names,results))\n",
    "print('testing',results,\"\\n\\n\");\n",
    "for key,value in results.items():\n",
    "    data_results['test_'+key]=value;\n",
    "\n",
    "data_results['number_of_parameters']=mpp.get_model_parameters(model);\n",
    "\n",
    "# final all json\n",
    "with open(os.path.join(output_dir,\"training_data_results.json\"), 'w') as f:\n",
    "    json.dump(data_results, f,indent=4);\n",
    "    f.close()\n",
    "\n",
    "# final test txt\n",
    "with open(os.path.join(output_dir,\"results_testing.txt\"), 'w') as f: \n",
    "    for key, value in results.items(): \n",
    "        f.write('%s=%s;\\n' % (key, value));\n",
    "    f.close()\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e25a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if   dataset_name=='fer2013':\n",
    "    target_names = ['angry','disgusted','fearful','happy','neutral','sad','surprised'];\n",
    "elif dataset_name=='affectnet':\n",
    "    target_names = ['neutral','happy','sad','surprised','fearful','disgusted','angry','unknown'];\n",
    "elif dataset_name=='mcfer_v1.0':\n",
    "    target_names = ['angry','disgusted','fearful','happy','neutral','sad','surprised'];\n",
    "elif dataset_name=='ber2024-face':\n",
    "    target_names = ['negative','neutral','pain','positive'];\n",
    "else:\n",
    "    print('Error in the dataset name.');\n",
    "    exit();\n",
    "\n",
    "# Predict\n",
    "Y_pred = model.predict(test_data_generator,verbose=1);\n",
    "y_pred = np.argmax(Y_pred, axis=1);\n",
    "\n",
    "# Confusion matrix\n",
    "\n",
    "CM=confusion_matrix(test_data_generator.classes, y_pred);\n",
    "\n",
    "fname=os.path.join(output_dir,\"confusion_matrix.eps\");\n",
    "fig, ax = plt.subplots(figsize=(8,6), dpi=100)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=CM, display_labels=target_names)\n",
    "disp.plot(ax=ax,cmap=plt.cm.Blues)\n",
    "plt.savefig(fname)\n",
    "\n",
    "cm_dict=dict();\n",
    "cm_dict['matrix']=CM.tolist();\n",
    "cm_dict['label']=target_names;\n",
    "# final all json\n",
    "with open(os.path.join(output_dir,\"confusion_matrix.json\"), 'w') as f:\n",
    "    json.dump(cm_dict, f,indent=4);\n",
    "    f.close()\n",
    "\n",
    "# Classification report\n",
    "fname=os.path.join(output_dir,\"classification_report.txt\")\n",
    "str_dat=classification_report(test_data_generator.classes, y_pred, target_names=target_names);\n",
    "print(str_dat)\n",
    "with open(fname, 'w') as f: \n",
    "    f.write('%s\\n' % str_dat);\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84facfa9-b65a-4fc8-85c7-025fd02f1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp_name='model_'+model_type+'.h5';\n",
    "\n",
    "os.rename(best_model_file,os.path.join(output_dir,tmp_name));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
