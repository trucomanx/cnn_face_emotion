{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_default_json_conf_file='cnn_face_emotion_kfold_default.json';\n",
    "print('\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f294d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../library');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e27cb9-4b9a-4bec-bd30-d9b7a23ec5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b2672",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load json conf json file\n",
    "fd = open(os.path.join('./',input_default_json_conf_file));\n",
    "DATA = json.load(fd);\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0f452-3278-49c0-9601-c8a443dbc32b",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83c3fa6-dbbb-4644-a12f-e497f971a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seed for the random variables\n",
    "seed_number=0;\n",
    "\n",
    "## Kfold \n",
    "K=DATA[\"kfold\"];        # Variable K of kfold\n",
    "enable_stratified=DATA[\"enable_stratified\"]; # True: Stratified kfold False: Enable kfold \n",
    "\n",
    "\n",
    "## Training hyperparameters\n",
    "EPOCAS=DATA[\"epochs\"];\n",
    "BATCH_SIZE=DATA[\"batch_size\"];\n",
    "\n",
    "## Model of network\n",
    "model_type  = DATA[\"dataset_name\"]; # 'mobilenet_v3' 'efficientnet_b3' 'inception_v3' 'inception_resnet_v2' 'resnet_v2_50' 'custom1' 'custom_inception' 'custom_residual1'  'custom_dense1'\n",
    "\n",
    "## Dataset name\n",
    "DATASET_NAME = DATA[\"model_type\"];\n",
    "\n",
    "dataset_base_dir = DATA[\"dataset_base_dir\"];\n",
    "\n",
    "dataset_labels_file = DATA[\"dataset_labels_file\"];\n",
    "\n",
    "## Output json file\n",
    "fold_status_file='fold_status.json';\n",
    "\n",
    "## Output\n",
    "output_base_dir = DATA[\"output_base_dir\"];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab5c325-9eda-4f6b-b4d8-99d2d433d896",
   "metadata": {},
   "source": [
    "# If command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32302454-de63-4f6c-be9f-a72aac1643d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dataset: fer2013\n",
      "model_type: mobilenet_v3\n",
      "    epochs: 80\n",
      "batch-size: 4\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(sys.argv)):\n",
    "    if   sys.argv[n]=='--model':\n",
    "        model_type=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--epochs':\n",
    "        EPOCAS=int(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--batch-size':\n",
    "        BATCH_SIZE=int(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--kfold':\n",
    "        K=int(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--enable-stratified':\n",
    "        enable_stratified=bool(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--dataset-name':\n",
    "        DATASET_NAME=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--dataset-dir':\n",
    "        dataset_base_dir=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--dataset-file':\n",
    "        dataset_labels_file=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--output-dir':\n",
    "        output_base_dir=sys.argv[n+1];\n",
    "\n",
    "print('       model_type:',model_type)\n",
    "print('           epochs:',EPOCAS)\n",
    "print('       batch-size:',BATCH_SIZE)\n",
    "print('                K:',K)\n",
    "print('enable_stratified:',enable_stratified)\n",
    "print('          dataset:',DATASET_NAME)\n",
    "print('      dataset-dir:',dataset_base_dir)\n",
    "print('     dataset-file:',dataset_labels_file)\n",
    "print('  output_base_dir:',output_base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1dee5-778a-4fd9-80de-90620bb33128",
   "metadata": {},
   "source": [
    "# Set seed of random variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ddef12f-6604-4c71-9473-15f328e954dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "tf.keras.utils.set_random_seed(seed_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da712f-5937-4965-9623-82c4ee139297",
   "metadata": {},
   "source": [
    "# Setting the cross-validation kfold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcab2262-3467-4ee3-86a8-9eda4f5ff726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "## Output\n",
    "output_dir = os.path.join(output_base_dir,DATASET_NAME,'cross-validation',model_type);\n",
    "print('output_dir:',output_dir)\n",
    "\n",
    "if enable_stratified:\n",
    "    kf = StratifiedKFold(n_splits = K, shuffle = True, random_state = seed_number);\n",
    "else:\n",
    "    kf  = KFold(n_splits = K, shuffle=True, random_state=seed_number); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a59004-739e-4760-bd91-ee3808207e3e",
   "metadata": {},
   "source": [
    "# Loading data of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1abe0e9b-ee46-40d8-97c3-12a1efc0cd1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/fernando/B0EA304AEA300EDA/Dados/Fernando/DATASET/fer2013/archive/train/training_labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7e7045b4b5fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load filenames and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_base_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset_labels_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Setting labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mY\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1219\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/fernando/B0EA304AEA300EDA/Dados/Fernando/DATASET/fer2013/archive/train/training_labels.csv'"
     ]
    }
   ],
   "source": [
    "# Load filenames and labels\n",
    "train_data = pd.read_csv(os.path.join(dataset_base_dir,dataset_labels_file));\n",
    "print(train_data)\n",
    "# Setting labels\n",
    "Y   = train_data[['label']];\n",
    "L=np.shape(Y)[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67beeb38-1ad1-455d-8a71-5900a1e88163",
   "metadata": {},
   "source": [
    "# Data augmentation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e3e68f-50e7-4f8c-9cd6-ae3261e8f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "idg    = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range = 10,\n",
    "                            width_shift_range= 0.07,\n",
    "                            height_shift_range= 0.07,\n",
    "                            horizontal_flip=True,\n",
    "                            shear_range=1.25,\n",
    "                            zoom_range = [0.9, 1.1] \n",
    "                            )\n",
    "\n",
    "idg_val= ImageDataGenerator(rescale=1./255 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757c163-8553-4377-a387-a9cd3131ac04",
   "metadata": {},
   "source": [
    "# Auxiliar function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6ca47-f504-47c5-99ad-db41692d40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5189cf-b447-4b0a-b9f3-56f304d6fdde",
   "metadata": {},
   "source": [
    "# Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a786de7-43ac-4597-92eb-d9eee66f81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir,exist_ok = True) \n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aff497",
   "metadata": {},
   "source": [
    "# Creating output status file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef66144",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_status_path=os.path.join(output_dir,fold_status_file);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf04e51-7a7b-4116-8e1e-04e5f358c5dc",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd68b8-e1aa-4ef4-af04-e05781f309ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lib_model as mpp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "list_train_index=[];\n",
    "list_val_index=[];\n",
    "for train_index, val_index in kf.split(np.zeros(L),Y):\n",
    "    list_train_index.append(train_index);\n",
    "    #print('train_index:',train_index);\n",
    "    list_val_index.append(val_index);\n",
    "    #print('val_index:',val_index);\n",
    "\n",
    "\n",
    "data_fold =  {  'val_categorical_accuracy': [],\n",
    "                'val_loss': [], \n",
    "                'train_categorical_accuracy': [],\n",
    "                'train_loss': [] };\n",
    "\n",
    "fold_var=1;\n",
    "\n",
    "if os.path.isfile(json_status_path):\n",
    "    # Read JSON file\n",
    "    with open(json_status_path) as data_file:\n",
    "        data_fold = json.load(data_file)\n",
    "        fold_var=len(data_fold['val_loss'])+1;\n",
    "    \n",
    "while fold_var<=K:\n",
    "    training_data   = train_data.iloc[list_train_index[fold_var-1]]\n",
    "    validation_data = train_data.iloc[list_val_index[fold_var-1]]\n",
    "\n",
    "    print('\\nFold',fold_var,'of',K);\n",
    "    print('length train:',len(list_train_index[fold_var-1]),'elements');\n",
    "    print('length val  :',len(list_val_index[fold_var-1]),'elements');\n",
    "\n",
    "    # CREATE NEW MODEL\n",
    "    if DATASET_NAME=='fer2013':\n",
    "        model, target_size = mpp.create_model('',model_type=model_type,nout=7);\n",
    "    elif DATASET_NAME=='affectnet':\n",
    "        model, target_size = mpp.create_model('',model_type=model_type,nout=8);\n",
    "    elif DATASET_NAME=='mcfer_v1.0':\n",
    "        model, target_size = mpp.create_model('',model_type=model_type,nout=7);\n",
    "    elif DATASET_NAME=='ber2024-face':\n",
    "        model, target_size = mpp.create_model('',model_type=model_type,nout=4);\n",
    "    else:\n",
    "        print('Error in the dataset name.');\n",
    "        exit();\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    train_data_generator = idg.flow_from_dataframe(training_data, \n",
    "                                                   directory = dataset_base_dir,\n",
    "                                                   target_size=target_size,\n",
    "                                                   x_col = \"filename\", \n",
    "                                                   y_col = \"label\",\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   shuffle = True);\n",
    "    \n",
    "    valid_data_generator  = idg_val.flow_from_dataframe(validation_data, \n",
    "                                                    directory = dataset_base_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    x_col = \"filename\", \n",
    "                                                    y_col = \"label\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    shuffle = True)\n",
    "    \n",
    "    #STEPS_BY_EPOCHS=len(train_data_generator);\n",
    "    \n",
    "    # COMPILE NEW MODEL\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    \n",
    "    # CREATE CALLBACKS\n",
    "    best_model_file=os.path.join(output_dir,get_model_name(fold_var));\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=best_model_file, \n",
    "                                                    save_weights_only=True,\n",
    "                                                    monitor='val_loss', \n",
    "                                                    save_best_only=True, \n",
    "                                                    verbose=1);\n",
    "    \n",
    "    log_dir = os.path.join(output_dir,\"logs\",\"fit\", \"fold\"+str(fold_var)+'_'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"));\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    \n",
    "    # There can be other callbacks, but just showing one because it involves the model name\n",
    "    # This saves the best model\n",
    "    # FIT THE MODEL\n",
    "    history = model.fit(train_data_generator,\n",
    "                        #steps_per_epoch=STEPS_BY_EPOCHS,\n",
    "                        epochs=EPOCAS,\n",
    "                        validation_data=valid_data_generator,\n",
    "                        callbacks=[checkpoint,tensorboard_callback],\n",
    "                        verbose=1\n",
    "                       );\n",
    "\n",
    "    #PLOT HISTORY\n",
    "    mpp.save_model_history( history,\n",
    "                            os.path.join(output_dir,\"historical_\"+str(fold_var)+\".csv\"), \n",
    "                            labels=['categorical_accuracy','loss'],\n",
    "                            show=False);\n",
    "    \n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model.load_weights(best_model_file);\n",
    "\n",
    "    # Evaluate training\n",
    "    results = model.evaluate(train_data_generator);\n",
    "    results = dict(zip(model.metrics_names,results));\n",
    "    print(\"Training:\\n\",results,\"\\n\\n\");\n",
    "    data_fold['train_categorical_accuracy'].append(results['categorical_accuracy']);\n",
    "    data_fold['train_loss'].append(results['loss']);\n",
    "\n",
    "    # Evaluate validation\n",
    "    results = model.evaluate(valid_data_generator)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "    print(\"Validation:\\n\",results,\"\\n\\n\");\n",
    "    data_fold['val_categorical_accuracy'].append(results['categorical_accuracy'])\n",
    "    data_fold['val_loss'].append(results['loss'])\n",
    "    \n",
    "    # Data fold\n",
    "    with open(json_status_path, 'w') as f:\n",
    "        json.dump(data_fold, f);\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a4b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fold['mean_val_categorical_accuracy'] = np.mean(data_fold['val_categorical_accuracy']);\n",
    "data_fold['std_val_categorical_accuracy']  = np.std(data_fold['val_categorical_accuracy']);\n",
    "\n",
    "data_fold['mean_val_loss'] = np.mean(data_fold['val_loss']);\n",
    "data_fold['std_val_loss']  = np.std(data_fold['val_loss']);\n",
    "\n",
    "data_fold['mean_train_categorical_accuracy'] = np.mean(data_fold['train_categorical_accuracy']);\n",
    "data_fold['std_train_categorical_accuracy']  = np.std(data_fold['train_categorical_accuracy']);\n",
    "\n",
    "data_fold['mean_train_loss'] = np.mean(data_fold['train_loss']);\n",
    "data_fold['std_train_loss']  = np.std(data_fold['train_loss']);\n",
    "\n",
    "print(data_fold)\n",
    "\n",
    "# Data fold\n",
    "with open(json_status_path, 'w') as f:\n",
    "    json.dump(data_fold, f,indent=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84facfa9-b65a-4fc8-85c7-025fd02f1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath=os.path.join(output_dir,\"final_stats.m\");\n",
    "mean_val_acc=mpp.save_model_stat_kfold(data_fold['val_categorical_accuracy'],data_fold['val_loss'], fpath);\n",
    "\n",
    "mpp.save_model_parameters(model, os.path.join(output_dir,'parameters_stats.m'));\n",
    "\n",
    "print(mean_val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
