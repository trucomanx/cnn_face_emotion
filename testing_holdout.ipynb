{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ce46fc-8392-4e0b-a820-3ce426fcc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform, sys, os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0f452-3278-49c0-9601-c8a443dbc32b",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83c3fa6-dbbb-4644-a12f-e497f971a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seed for the random variables\n",
    "seed_number=0;\n",
    "\n",
    "BATCH_SIZE=32\n",
    "\n",
    "## Model of network\n",
    "#model_type = 'efficientnet_b3'\n",
    "model_type = 'mobilenet_v3';\n",
    "#model_type = 'inception_v3';\n",
    "#model_type = 'inception_resnet_v2';\n",
    "#model_type = 'resnet_v2_50';\n",
    "\n",
    "times=1;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc2740f-5e81-4e9a-8cd0-544ff70bfb10",
   "metadata": {},
   "source": [
    "# Endere√ßos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13bf154e-09c5-45b7-ad19-b7ecefb656aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_base_dir: /mnt/boveda/DATASETs/FACE-EMOTION/fer2013/archive/test\n",
      "output_base_dir: /mnt/boveda/DOCTORADO2/cnn_face_emotion/test_holdout\n",
      "path_of_best_model_file: /home/fernando/Downloads/TESIS-DOUTORADO-2/PESQUISA/programs-tese/cnn_face_emotion/library/models\n"
     ]
    }
   ],
   "source": [
    "## Dataset \n",
    "if platform.system()=='Linux':\n",
    "    if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "        dataset_base_dir    = 'fer2013/archive/test';\n",
    "    elif 'microsoft-standard' in platform.uname().release:\n",
    "        dataset_base_dir    = '/mnt/c/Dados/Fernando/DATASET/fer2013/archive/test';\n",
    "    else:\n",
    "        dataset_base_dir    = '/mnt/boveda/DATASETs/FACE-EMOTION/fer2013/archive/test';\n",
    "else:\n",
    "    dataset_base_dir    = 'C:\\\\Dados\\\\Fernando\\\\DATASET\\\\fer2013\\\\archive\\\\test';\n",
    "\n",
    "print('dataset_base_dir:',dataset_base_dir)\n",
    "\n",
    "## Output\n",
    "if platform.system()=='Linux':\n",
    "    if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "        output_base_dir = 'OUTPUTS/cnn_face_emotion/test_holdout';\n",
    "    elif 'microsoft-standard' in platform.uname().release:\n",
    "        output_base_dir = '/mnt/c/Dados/Fernando/OUTPUTS/cnn_face_emotion/test_holdout';\n",
    "    else:\n",
    "        output_base_dir = '/mnt/boveda/DOCTORADO2/cnn_face_emotion/test_holdout';\n",
    "else:\n",
    "    output_base_dir = 'C:\\\\Dados\\\\Fernando\\\\OUTPUTS\\\\cnn_face_emotion\\\\test_holdout';\n",
    "\n",
    "print('output_base_dir:',output_base_dir)\n",
    "\n",
    "\n",
    "# Best model\n",
    "if platform.system()=='Linux':\n",
    "    if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "        path_of_best_model_file = 'cnn_face_emotion/library/models';\n",
    "    elif 'microsoft-standard' in platform.uname().release:\n",
    "        path_of_best_model_file = '/mnt/c/Dados/Fernando/CODE/PESQUISA/programs-tese/cnn_face_emotion/library/models';\n",
    "    else:\n",
    "        path_of_best_model_file='/home/fernando/Downloads/TESIS-DOUTORADO-2/PESQUISA/programs-tese/cnn_face_emotion/library/models';\n",
    "else:\n",
    "    path_of_best_model_file='C:\\\\Dados\\\\Fernando\\\\CODE\\\\PESQUISA\\\\programs-tese\\\\cnn_face_emotion\\\\library\\\\models';\n",
    "\n",
    "print('path_of_best_model_file:',path_of_best_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e08f904-53f7-4d9e-95ad-dcb0397799c9",
   "metadata": {},
   "source": [
    "# Bibliotecas externas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3410f40c-893b-449d-b024-7781e0d76733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff9cb56-2b1e-4fce-b378-6f33cae19622",
   "metadata": {},
   "source": [
    "# Biblioteca local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c554098-8f30-478f-a736-b9b387fdd1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('library');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc12f1-6c56-4e35-b126-8979486b695b",
   "metadata": {},
   "source": [
    "# If command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2087e4ea-a8e4-4ed5-b2f7-2b391f054575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_type: mobilenet_v3\n",
      "times: 1\n"
     ]
    }
   ],
   "source": [
    "#print('cmd entry:', sys.argv)\n",
    "\n",
    "for n in range(len(sys.argv)):\n",
    "    if sys.argv[n]=='--model':\n",
    "        model_type=sys.argv[n+1];\n",
    "    if sys.argv[n]=='--times':\n",
    "        times=int(sys.argv[n+1]);\n",
    "\n",
    "\n",
    "best_model_file=os.path.join(path_of_best_model_file,'modelo_'+model_type+'.h5');\n",
    "\n",
    "print('model_type:',model_type)\n",
    "print('times:',times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1dee5-778a-4fd9-80de-90620bb33128",
   "metadata": {},
   "source": [
    "# Set seed of random variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ddef12f-6604-4c71-9473-15f328e954dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "tf.keras.utils.set_random_seed(seed_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67beeb38-1ad1-455d-8a71-5900a1e88163",
   "metadata": {},
   "source": [
    "# Data augmentation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e3e68f-50e7-4f8c-9cd6-ae3261e8f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "idg_test= ImageDataGenerator(rescale=1./255 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5189cf-b447-4b0a-b9f3-56f304d6fdde",
   "metadata": {},
   "source": [
    "# Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a786de7-43ac-4597-92eb-d9eee66f81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dir = os.path.join(output_base_dir,'holdout');\n",
    "output_dir = os.path.join(output_base_dir,model_type);\n",
    "\n",
    "try: \n",
    "    os.makedirs(output_dir) \n",
    "except: \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf04e51-7a7b-4116-8e1e-04e5f358c5dc",
   "metadata": {},
   "source": [
    "# Create new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d629ba9-d621-4905-a88f-a0730d6c1802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded layer with mobilenet_v3\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1024)              1529968   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                32800     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,562,999\n",
      "Trainable params: 1,550,887\n",
      "Non-trainable params: 12,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import lib_model as mpp\n",
    "\n",
    "model, target_size = mpp.create_model('',model_type=model_type);\n",
    "model.summary()\n",
    "\n",
    "mpp.save_model_parameters(model, os.path.join(output_dir,'parameters_stats.m'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59917a-4069-439f-9108-e5b139498b01",
   "metadata": {},
   "source": [
    "# Defining directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac8f2152-96da-447d-b437-84f11e12937f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7173 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data_generator  = idg_test.flow_from_directory(dataset_base_dir, \n",
    "                                                    target_size=target_size,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True\n",
    "                                                    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1be572-b9c7-422c-9518-53735f9425c7",
   "metadata": {},
   "source": [
    "# Compile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13cd68b8-e1aa-4ef4-af04-e05781f309ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE NEW MODEL\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083be078-c76e-423a-a538-6e5c6c9cda8c",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33e25913-47a1-4e14-b560-2c5037904a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytictoc import TicToc\n",
    "t = TicToc() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97efa97-b910-43a5-97ee-a18a230305e7",
   "metadata": {},
   "source": [
    "# Evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d4f6536-46f0-4c89-b98f-7cb5a4075cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 7173\n",
      "{'loss': 1.3863438367843628, 'categorical_accuracy': 0.6750313639640808} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LOAD BEST MODEL to evaluate the performance of the model\n",
    "model.load_weights(best_model_file);\n",
    "\n",
    "\n",
    "L=test_data_generator.samples;\n",
    "print('L:',L);\n",
    "\n",
    "t.tic();\n",
    "for m in range(times):\n",
    "    results = model.evaluate(test_data_generator,verbose=0)\n",
    "t0=t.tocvalue();\n",
    "\n",
    "results = dict(zip(model.metrics_names,results))\n",
    "print(results,\"\\n\\n\");\n",
    "\n",
    "\n",
    "with open(os.path.join(output_dir,\"results_testing.m\"), 'w') as f: \n",
    "    for key, value in results.items(): \n",
    "        f.write('%s=%s;\\n' % (key, value));\n",
    "    f.write('delayms=%s;\\n' % (t0*1000.0/(times*L)));\n",
    "\n",
    "tf.keras.backend.clear_session()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
