{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dcc51ca",
   "metadata": {},
   "source": [
    "!git clone https://github.com/trucomanx/cnn_face_emotion.git\n",
    "!mkdir -p OUTPUTS/cnn_face_emotion/cross-validation\n",
    "!wget https://www.dropbox.com/s/23tutsg2m9o78bp/fer2013.zip\n",
    "!unzip -n fer2013.zip\n",
    "!rm fer2013.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93cc48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0f452-3278-49c0-9601-c8a443dbc32b",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83c3fa6-dbbb-4644-a12f-e497f971a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seed for the random variables\n",
    "seed_number=0;\n",
    "\n",
    "\n",
    "\n",
    "## Training hyperparameters\n",
    "EPOCAS=50;\n",
    "BATCH_SIZE=16;\n",
    "\n",
    "## Model of network\n",
    "#model_type  = 'mobilenet_v3';\n",
    "model_type = 'efficientnet_b3'\n",
    "#model_type = 'inception_v3';\n",
    "#model_type = 'inception_resnet_v2';\n",
    "#model_type = 'resnet_v2_50';\n",
    "#model_type = 'custom1'\n",
    "#model_type = 'custom_inception'\n",
    "#model_type = 'custom_residual1'\n",
    "#model_type = 'custom_dense1'\n",
    "\n",
    "DATASET_NAME = 'mcfer_v1.0';#'fer2013';\n",
    "\n",
    "\n",
    "dataset_labels_file = 'training_labels.csv';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05a2eb",
   "metadata": {},
   "source": [
    "# Bibliotecas externas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3410f40c-893b-449d-b024-7781e0d76733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 17:40:58.494223: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-15 17:40:59.614810: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fernando/anaconda3/lib/\n",
      "2023-05-15 17:40:59.614980: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fernando/anaconda3/lib/\n",
      "2023-05-15 17:40:59.614985: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c28ba2",
   "metadata": {},
   "source": [
    "# Biblioteca local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ce46fc-8392-4e0b-a820-3ce426fcc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    sys.path.append('cnn_face_emotion/library');\n",
    "else:\n",
    "    sys.path.append('library');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0c9a8",
   "metadata": {},
   "source": [
    "# Uso de GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "436cdeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 17:41:02.354568: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 17:41:02.607254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 17:41:02.607354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f43c5",
   "metadata": {},
   "source": [
    "# EndereÃ§os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05ffd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_base_dir: /media/fernando/B0EA304AEA300EDA/Dados/Fernando/DATASET/mcfer_v1.0/archive/train\n",
      "dataset_base_test_dir: /media/fernando/B0EA304AEA300EDA/Dados/Fernando/DATASET/mcfer_v1.0/archive/test\n",
      "output_base_dir: /media/fernando/B0EA304AEA300EDA/Dados/Fernando/OUTPUTS/cnn_face_emotion_mcfer_v1.0/training_holdout\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Dataset \n",
    "if platform.system()=='Linux':\n",
    "    if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "        dataset_base_dir_raw = './';\n",
    "    elif 'microsoft-standard' in platform.uname().release:\n",
    "        dataset_base_dir_raw = '/mnt/c/Dados/Fernando/DATASET';\n",
    "    else:\n",
    "        dataset_base_dir_raw = '/media/fernando/B0EA304AEA300EDA/Dados/Fernando/DATASET';\n",
    "else:\n",
    "    dataset_base_dir_raw     = 'C:\\\\Dados\\\\Fernando\\\\DATASET';\n",
    "\n",
    "if DATASET_NAME=='fer2013':\n",
    "    RELATIVE_DIR_TRAIN=os.path.join(DATASET_NAME,'archive','train');\n",
    "    RELATIVE_DIR_TEST =os.path.join(DATASET_NAME,'archive','test');\n",
    "elif DATASET_NAME=='affectnet':\n",
    "    RELATIVE_DIR_TRAIN=os.path.join('AffectNet-Sample','input','affectnetsample','train_class');\n",
    "    RELATIVE_DIR_TEST =os.path.join('AffectNet-Sample','input','affectnetsample','val_class');\n",
    "elif DATASET_NAME=='mcfer_v1.0':\n",
    "    RELATIVE_DIR_TRAIN=os.path.join(DATASET_NAME,'archive','train');\n",
    "    RELATIVE_DIR_TEST =os.path.join(DATASET_NAME,'archive','test');\n",
    "else:\n",
    "    print('Error in the dataset name:',DATASET_NAME);\n",
    "    exit();\n",
    "'''    \n",
    "if platform.system()=='Linux':\n",
    "    if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "        dataset_base_dir     = 'fer2013/archive/train';\n",
    "        dataset_base_test_dir= 'fer2013/archive/test';\n",
    "    elif 'microsoft-standard' in platform.uname().release:\n",
    "        dataset_base_dir     = '/mnt/c/Dados/Fernando/DATASET/fer2013/archive/train';\n",
    "        dataset_base_test_dir= '/mnt/c/Dados/Fernando/DATASET/fer2013/archive/test';\n",
    "    else:\n",
    "        dataset_base_dir     = '/mnt/boveda/DATASETs/FACE-EMOTION/fer2013/archive/train';\n",
    "        dataset_base_test_dir= '/mnt/boveda/DATASETs/FACE-EMOTION/fer2013/archive/test';\n",
    "else:\n",
    "    dataset_base_dir     = 'C:\\\\Dados\\\\Fernando\\\\DATASET\\\\fer2013\\\\archive\\\\train';\n",
    "    dataset_base_test_dir= 'C:\\\\Dados\\\\Fernando\\\\DATASET\\\\fer2013\\\\archive\\\\test';\n",
    "'''\n",
    "\n",
    "dataset_base_dir = os.path.join(dataset_base_dir_raw,RELATIVE_DIR_TRAIN);\n",
    "dataset_base_test_dir = os.path.join(dataset_base_dir_raw,RELATIVE_DIR_TEST);\n",
    "\n",
    "print('dataset_base_dir:',dataset_base_dir)\n",
    "print('dataset_base_test_dir:',dataset_base_test_dir)\n",
    "\n",
    "## Output\n",
    "if platform.system()=='Linux':\n",
    "    if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "        output_base_dir_raw = 'OUTPUTS';\n",
    "    elif 'microsoft-standard' in platform.uname().release:\n",
    "        output_base_dir_raw = '/mnt/c/Dados/Fernando/OUTPUTS';\n",
    "    else:\n",
    "        output_base_dir_raw = '/media/fernando/B0EA304AEA300EDA/Dados/Fernando/OUTPUTS';\n",
    "else:\n",
    "    output_base_dir_raw = 'C:\\\\Dados\\\\Fernando\\\\OUTPUTS';\n",
    "\n",
    "    \n",
    "RELATIVE_DIR=os.path.join('cnn_face_emotion_'+DATASET_NAME,'training_holdout');\n",
    "output_base_dir = os.path.join(output_base_dir_raw,RELATIVE_DIR); \n",
    "\n",
    "print('output_base_dir:',output_base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad2f2a4-d4b2-436d-b90d-1e891d47b74f",
   "metadata": {},
   "source": [
    "# Print vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8850b99-60ad-4727-862e-34b80c259ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_type: efficientnet_b3\n",
      "    epochs: 50\n",
      "batch-size: 16\n"
     ]
    }
   ],
   "source": [
    "print('model_type:',model_type)\n",
    "print('    epochs:',EPOCAS)\n",
    "print('batch-size:',BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1dee5-778a-4fd9-80de-90620bb33128",
   "metadata": {},
   "source": [
    "# Set seed of random variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ddef12f-6604-4c71-9473-15f328e954dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "tf.keras.utils.set_random_seed(seed_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a59004-739e-4760-bd91-ee3808207e3e",
   "metadata": {},
   "source": [
    "# Loading data of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1abe0e9b-ee46-40d8-97c3-12a1efc0cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    filename      label\n",
      "0      disgusted/awful/affectnet_0036766.png  disgusted\n",
      "1                         sad/crying/im5.png        sad\n",
      "2       fearful/attention-fearful/im32_1.png    fearful\n",
      "3                neutral/attention/im2_1.png    neutral\n",
      "4             angry/angry-disgusted/im19.png      angry\n",
      "...                                      ...        ...\n",
      "24231         happy/light-smile/im4724_1.png      happy\n",
      "24232           happy/light-smile/im4742.png      happy\n",
      "24233           happy/light-smile/im4809.png      happy\n",
      "24234           happy/light-smile/im5535.png      happy\n",
      "24235           happy/light-smile/im5545.png      happy\n",
      "\n",
      "[24236 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load filenames and labels\n",
    "train_data = pd.read_csv(os.path.join(dataset_base_dir,dataset_labels_file));\n",
    "print(train_data)\n",
    "# Setting labels\n",
    "Y = train_data[['label']];\n",
    "L=np.shape(Y)[0];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da712f-5937-4965-9623-82c4ee139297",
   "metadata": {},
   "source": [
    "# Setting the cross-validation split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcab2262-3467-4ee3-86a8-9eda4f5ff726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "\n",
    "training_data, validation_data = train_test_split(train_data, test_size=0.2,shuffle=True, stratify=Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67beeb38-1ad1-455d-8a71-5900a1e88163",
   "metadata": {},
   "source": [
    "# Data augmentation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2e3e68f-50e7-4f8c-9cd6-ae3261e8f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "idg    = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range = 10,\n",
    "                            width_shift_range= 0.07,\n",
    "                            height_shift_range= 0.07,\n",
    "                            horizontal_flip=True,\n",
    "                            shear_range=1.25,\n",
    "                            zoom_range = [0.75, 1.25],\n",
    "                            validation_split=0.25\n",
    "                            )\n",
    "\n",
    "#idg_val= ImageDataGenerator(rescale=1./255 )\n",
    "\n",
    "idg_test= ImageDataGenerator(rescale=1./255 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5189cf-b447-4b0a-b9f3-56f304d6fdde",
   "metadata": {},
   "source": [
    "# Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a786de7-43ac-4597-92eb-d9eee66f81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dir = os.path.join(output_base_dir,'holdout');\n",
    "output_dir = os.path.join(output_base_dir,'holdout_'+model_type);\n",
    "\n",
    "try: \n",
    "    os.makedirs(output_dir) \n",
    "except: \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf04e51-7a7b-4116-8e1e-04e5f358c5dc",
   "metadata": {},
   "source": [
    "# Create new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d629ba9-d621-4905-a88f-a0730d6c1802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 17:41:05.874179: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-15 17:41:05.875048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 17:41:05.875222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 17:41:05.875299: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 17:41:06.222701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 17:41:06.222821: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 17:41:06.222906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 17:41:06.222972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9865 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded layer with efficientnet_b3\n",
      "WARNING:tensorflow:From /home/fernando/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fernando/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1536)              10783528  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                49184     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,832,943\n",
      "Trainable params: 10,745,647\n",
      "Non-trainable params: 87,296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import lib_model as mpp\n",
    "\n",
    "model, target_size = mpp.create_model('',model_type=model_type);\n",
    "model.summary()\n",
    "\n",
    "mpp.save_model_parameters(model, os.path.join(output_dir,'parameters_stats.m'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59917a-4069-439f-9108-e5b139498b01",
   "metadata": {},
   "source": [
    "# Defining directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac8f2152-96da-447d-b437-84f11e12937f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19388 validated image filenames belonging to 7 classes.\n",
      "Found 4848 validated image filenames belonging to 7 classes.\n",
      "Found 6709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data_generator = idg.flow_from_dataframe(training_data, \n",
    "                                               directory = dataset_base_dir,\n",
    "                                               target_size=target_size,\n",
    "                                               x_col = \"filename\", \n",
    "                                               y_col = \"label\",\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               shuffle = True);\n",
    "\n",
    "valid_data_generator  = idg.flow_from_dataframe(validation_data, \n",
    "                                                    directory = dataset_base_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    x_col = \"filename\", \n",
    "                                                    y_col = \"label\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    shuffle = True);\n",
    "\n",
    "test_data_generator  = idg_test.flow_from_directory(dataset_base_test_dir, \n",
    "                                                    target_size=target_size,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True\n",
    "                                                    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1be572-b9c7-422c-9518-53735f9425c7",
   "metadata": {},
   "source": [
    "# Train and validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd68b8-e1aa-4ef4-af04-e05781f309ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 17:41:38.871758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-05-15 17:41:39.535857: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-15 17:41:40.857884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-15 17:41:40.860121: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x922136d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-15 17:41:40.860136: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-05-15 17:41:40.863301: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-15 17:41:40.908514: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-15 17:41:40.933809: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1212/1212 [==============================] - ETA: 0s - loss: 1.4947 - categorical_accuracy: 0.5336 - categorical_crossentropy: 1.3094\n",
      "Epoch 1: val_categorical_crossentropy improved from inf to 1.14356, saving model to /media/fernando/B0EA304AEA300EDA/Dados/Fernando/OUTPUTS/cnn_face_emotion_mcfer_v1.0/training_holdout/holdout_efficientnet_b3/model.h5\n",
      "1212/1212 [==============================] - 466s 347ms/step - loss: 1.4947 - categorical_accuracy: 0.5336 - categorical_crossentropy: 1.3094 - val_loss: 1.3307 - val_categorical_accuracy: 0.5963 - val_categorical_crossentropy: 1.1436\n",
      "Epoch 2/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 1.2587 - categorical_accuracy: 0.6104 - categorical_crossentropy: 1.0726\n",
      "Epoch 2: val_categorical_crossentropy improved from 1.14356 to 1.05823, saving model to /media/fernando/B0EA304AEA300EDA/Dados/Fernando/OUTPUTS/cnn_face_emotion_mcfer_v1.0/training_holdout/holdout_efficientnet_b3/model.h5\n",
      "1212/1212 [==============================] - 412s 340ms/step - loss: 1.2587 - categorical_accuracy: 0.6104 - categorical_crossentropy: 1.0726 - val_loss: 1.2425 - val_categorical_accuracy: 0.6157 - val_categorical_crossentropy: 1.0582\n",
      "Epoch 3/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 1.1769 - categorical_accuracy: 0.6415 - categorical_crossentropy: 0.9945\n",
      "Epoch 3: val_categorical_crossentropy improved from 1.05823 to 0.96510, saving model to /media/fernando/B0EA304AEA300EDA/Dados/Fernando/OUTPUTS/cnn_face_emotion_mcfer_v1.0/training_holdout/holdout_efficientnet_b3/model.h5\n",
      "1212/1212 [==============================] - 403s 333ms/step - loss: 1.1769 - categorical_accuracy: 0.6415 - categorical_crossentropy: 0.9945 - val_loss: 1.1449 - val_categorical_accuracy: 0.6555 - val_categorical_crossentropy: 0.9651\n",
      "Epoch 4/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 1.1203 - categorical_accuracy: 0.6584 - categorical_crossentropy: 0.9429\n",
      "Epoch 4: val_categorical_crossentropy improved from 0.96510 to 0.94210, saving model to /media/fernando/B0EA304AEA300EDA/Dados/Fernando/OUTPUTS/cnn_face_emotion_mcfer_v1.0/training_holdout/holdout_efficientnet_b3/model.h5\n",
      "1212/1212 [==============================] - 416s 343ms/step - loss: 1.1203 - categorical_accuracy: 0.6584 - categorical_crossentropy: 0.9429 - val_loss: 1.1167 - val_categorical_accuracy: 0.6599 - val_categorical_crossentropy: 0.9421\n",
      "Epoch 5/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 1.0744 - categorical_accuracy: 0.6757 - categorical_crossentropy: 0.9017\n",
      "Epoch 5: val_categorical_crossentropy improved from 0.94210 to 0.91658, saving model to /media/fernando/B0EA304AEA300EDA/Dados/Fernando/OUTPUTS/cnn_face_emotion_mcfer_v1.0/training_holdout/holdout_efficientnet_b3/model.h5\n",
      "1212/1212 [==============================] - 402s 331ms/step - loss: 1.0744 - categorical_accuracy: 0.6757 - categorical_crossentropy: 0.9017 - val_loss: 1.0870 - val_categorical_accuracy: 0.6733 - val_categorical_crossentropy: 0.9166\n",
      "Epoch 6/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 1.0348 - categorical_accuracy: 0.6850 - categorical_crossentropy: 0.8661\n",
      "Epoch 6: val_categorical_crossentropy did not improve from 0.91658\n",
      "1212/1212 [==============================] - 381s 314ms/step - loss: 1.0348 - categorical_accuracy: 0.6850 - categorical_crossentropy: 0.8661 - val_loss: 1.0902 - val_categorical_accuracy: 0.6741 - val_categorical_crossentropy: 0.9225\n",
      "Epoch 7/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 1.0021 - categorical_accuracy: 0.6985 - categorical_crossentropy: 0.8353\n",
      "Epoch 7: val_categorical_crossentropy did not improve from 0.91658\n",
      "1212/1212 [==============================] - 381s 314ms/step - loss: 1.0021 - categorical_accuracy: 0.6985 - categorical_crossentropy: 0.8353 - val_loss: 1.1300 - val_categorical_accuracy: 0.6574 - val_categorical_crossentropy: 0.9637\n",
      "Epoch 8/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 0.9812 - categorical_accuracy: 0.7090 - categorical_crossentropy: 0.8152\n",
      "Epoch 8: val_categorical_crossentropy did not improve from 0.91658\n",
      "1212/1212 [==============================] - 379s 313ms/step - loss: 0.9812 - categorical_accuracy: 0.7090 - categorical_crossentropy: 0.8152 - val_loss: 1.0931 - val_categorical_accuracy: 0.6663 - val_categorical_crossentropy: 0.9273\n",
      "Epoch 9/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 0.9561 - categorical_accuracy: 0.7138 - categorical_crossentropy: 0.7905\n",
      "Epoch 9: val_categorical_crossentropy improved from 0.91658 to 0.85562, saving model to /media/fernando/B0EA304AEA300EDA/Dados/Fernando/OUTPUTS/cnn_face_emotion_mcfer_v1.0/training_holdout/holdout_efficientnet_b3/model.h5\n",
      "1212/1212 [==============================] - 381s 314ms/step - loss: 0.9561 - categorical_accuracy: 0.7138 - categorical_crossentropy: 0.7905 - val_loss: 1.0212 - val_categorical_accuracy: 0.7030 - val_categorical_crossentropy: 0.8556\n",
      "Epoch 10/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 0.9228 - categorical_accuracy: 0.7255 - categorical_crossentropy: 0.7554\n",
      "Epoch 10: val_categorical_crossentropy improved from 0.85562 to 0.83928, saving model to /media/fernando/B0EA304AEA300EDA/Dados/Fernando/OUTPUTS/cnn_face_emotion_mcfer_v1.0/training_holdout/holdout_efficientnet_b3/model.h5\n",
      "1212/1212 [==============================] - 381s 315ms/step - loss: 0.9228 - categorical_accuracy: 0.7255 - categorical_crossentropy: 0.7554 - val_loss: 1.0074 - val_categorical_accuracy: 0.7110 - val_categorical_crossentropy: 0.8393\n",
      "Epoch 11/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 0.9117 - categorical_accuracy: 0.7325 - categorical_crossentropy: 0.7434\n",
      "Epoch 11: val_categorical_crossentropy did not improve from 0.83928\n",
      "1212/1212 [==============================] - 379s 313ms/step - loss: 0.9117 - categorical_accuracy: 0.7325 - categorical_crossentropy: 0.7434 - val_loss: 1.0253 - val_categorical_accuracy: 0.6943 - val_categorical_crossentropy: 0.8558\n",
      "Epoch 12/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 0.8923 - categorical_accuracy: 0.7349 - categorical_crossentropy: 0.7238\n",
      "Epoch 12: val_categorical_crossentropy did not improve from 0.83928\n",
      "1212/1212 [==============================] - 383s 316ms/step - loss: 0.8923 - categorical_accuracy: 0.7349 - categorical_crossentropy: 0.7238 - val_loss: 1.0095 - val_categorical_accuracy: 0.7118 - val_categorical_crossentropy: 0.8413\n",
      "Epoch 13/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 0.8758 - categorical_accuracy: 0.7428 - categorical_crossentropy: 0.7061\n",
      "Epoch 13: val_categorical_crossentropy did not improve from 0.83928\n",
      "1212/1212 [==============================] - 382s 315ms/step - loss: 0.8758 - categorical_accuracy: 0.7428 - categorical_crossentropy: 0.7061 - val_loss: 1.0244 - val_categorical_accuracy: 0.6980 - val_categorical_crossentropy: 0.8540\n",
      "Epoch 14/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 0.8577 - categorical_accuracy: 0.7517 - categorical_crossentropy: 0.6865\n",
      "Epoch 14: val_categorical_crossentropy improved from 0.83928 to 0.83876, saving model to /media/fernando/B0EA304AEA300EDA/Dados/Fernando/OUTPUTS/cnn_face_emotion_mcfer_v1.0/training_holdout/holdout_efficientnet_b3/model.h5\n",
      "1212/1212 [==============================] - 382s 315ms/step - loss: 0.8577 - categorical_accuracy: 0.7517 - categorical_crossentropy: 0.6865 - val_loss: 1.0107 - val_categorical_accuracy: 0.7098 - val_categorical_crossentropy: 0.8388\n",
      "Epoch 15/50\n",
      "1212/1212 [==============================] - ETA: 0s - loss: 0.8511 - categorical_accuracy: 0.7520 - categorical_crossentropy: 0.6777\n",
      "Epoch 15: val_categorical_crossentropy did not improve from 0.83876\n",
      "1212/1212 [==============================] - 385s 318ms/step - loss: 0.8511 - categorical_accuracy: 0.7520 - categorical_crossentropy: 0.6777 - val_loss: 1.0276 - val_categorical_accuracy: 0.6958 - val_categorical_crossentropy: 0.8528\n",
      "Epoch 16/50\n",
      " 345/1212 [=======>......................] - ETA: 3:58 - loss: 0.8315 - categorical_accuracy: 0.7665 - categorical_crossentropy: 0.6568"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#STEPS_BY_EPOCHS=len(train_data_generator);\n",
    "\n",
    "# COMPILE NEW MODEL\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy','categorical_crossentropy'])\n",
    "\n",
    "# CREATE CALLBACKS\n",
    "best_model_file=os.path.join(output_dir,'model.h5');\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=best_model_file, \n",
    "                                                save_weights_only=True,\n",
    "                                                monitor='val_categorical_crossentropy', \n",
    "                                                save_best_only=True, \n",
    "                                                verbose=1);\n",
    "\n",
    "log_dir = os.path.join(output_dir,\"logs\",\"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"));\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# There can be other callbacks, but just showing one because it involves the model name\n",
    "# This saves the best model\n",
    "# FIT THE MODEL\n",
    "history = model.fit(train_data_generator,\n",
    "                    #steps_per_epoch=STEPS_BY_EPOCHS,\n",
    "                    epochs=EPOCAS,\n",
    "                    validation_data=valid_data_generator,\n",
    "                    callbacks=[checkpoint,tensorboard_callback],\n",
    "                    verbose=1\n",
    "                   );\n",
    "\n",
    "\n",
    "mpp.save_model_history(history,os.path.join(output_dir,\"historical.csv\"));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083be078-c76e-423a-a538-6e5c6c9cda8c",
   "metadata": {},
   "source": [
    "# Evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f6536-46f0-4c89-b98f-7cb5a4075cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD BEST MODEL to evaluate the performance of the model\n",
    "model.load_weights(best_model_file);\n",
    "\n",
    "results = model.evaluate(test_data_generator)\n",
    "results = dict(zip(model.metrics_names,results))\n",
    "print(results,\"\\n\\n\");\n",
    "\n",
    "with open(os.path.join(output_dir,\"results_testing.txt\"), 'w') as f: \n",
    "    for key, value in results.items(): \n",
    "        f.write('%s=%s;\\n' % (key, value));\n",
    "\n",
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84facfa9-b65a-4fc8-85c7-025fd02f1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp_name='modelo_'+model_type+'.h5';\n",
    "\n",
    "os.rename(best_model_file,os.path.join(output_dir,tmp_name));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f70e376-46ee-40aa-bd19-1ea149d0a3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fecf1b-cef9-463b-b76d-ff614de2be37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
