{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3410f40c-893b-449d-b024-7781e0d76733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ce46fc-8392-4e0b-a820-3ce426fcc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('library');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0f452-3278-49c0-9601-c8a443dbc32b",
   "metadata": {},
   "source": [
    "# Variable globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83c3fa6-dbbb-4644-a12f-e497f971a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seed for the random variables\n",
    "seed_number=0;\n",
    "\n",
    "## Dataset \n",
    "dataset_base_dir     = '/mnt/boveda/DATASETs/PATIENT-IMAGES/patient_people/train';\n",
    "dataset_labels_file  = 'training_labels.csv';\n",
    "\n",
    "dataset_base_test_dir= '/mnt/boveda/DATASETs/PATIENT-IMAGES/patient_people/test';\n",
    "\n",
    "\n",
    "## Training hyperparameters\n",
    "EPOCAS=50;\n",
    "BATCH_SIZE=32;\n",
    "\n",
    "## Model of network\n",
    "#model_type  = 'mobilenet_v3';\n",
    "#model_type = 'efficientnet_b3'\n",
    "#model_type = 'inception_v3';\n",
    "#model_type = 'inception_resnet_v2';\n",
    "#model_type = 'resnet_v2_50';\n",
    "#model_type = 'custom1'\n",
    "#model_type = 'custom_inception'\n",
    "#model_type = 'custom_residual1'\n",
    "model_type = 'custom_dense1'\n",
    "\n",
    "## Output\n",
    "output_base_dir = '/mnt/boveda/DOCTORADO2/cnn_patient_people/train';\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1dee5-778a-4fd9-80de-90620bb33128",
   "metadata": {},
   "source": [
    "# Set seed of random variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ddef12f-6604-4c71-9473-15f328e954dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "tf.keras.utils.set_random_seed(seed_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a59004-739e-4760-bd91-ee3808207e3e",
   "metadata": {},
   "source": [
    "# Loading data of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1abe0e9b-ee46-40d8-97c3-12a1efc0cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    filename    label\n",
      "0       people/filename1.png   people\n",
      "1      patient/filename1.png  patient\n",
      "2       people/filename2.png   people\n",
      "3      patient/filename2.png  patient\n",
      "4       people/filename3.png   people\n",
      "..                       ...      ...\n",
      "626  patient/filename456.png  patient\n",
      "627  patient/filename457.png  patient\n",
      "628  patient/filename458.png  patient\n",
      "629  patient/filename459.png  patient\n",
      "630  patient/filename460.png  patient\n",
      "\n",
      "[631 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load filenames and labels\n",
    "train_data = pd.read_csv(os.path.join(dataset_base_dir,dataset_labels_file));\n",
    "print(train_data)\n",
    "# Setting labels\n",
    "Y = train_data[['label']];\n",
    "L=np.shape(Y)[0];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da712f-5937-4965-9623-82c4ee139297",
   "metadata": {},
   "source": [
    "# Setting the cross-validation split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcab2262-3467-4ee3-86a8-9eda4f5ff726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "training_data, validation_data = train_test_split(train_data, test_size=0.2,shuffle=True, stratify=Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67beeb38-1ad1-455d-8a71-5900a1e88163",
   "metadata": {},
   "source": [
    "# Data augmentation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e3e68f-50e7-4f8c-9cd6-ae3261e8f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "idg    = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range = 10,\n",
    "                            width_shift_range= 0.07,\n",
    "                            height_shift_range= 0.07,\n",
    "                            horizontal_flip=True,\n",
    "                            shear_range=1.25,\n",
    "                            zoom_range = [0.75, 1.25] \n",
    "                            )\n",
    "\n",
    "idg_val= ImageDataGenerator(rescale=1./255 )\n",
    "\n",
    "idg_test= ImageDataGenerator(rescale=1./255 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5189cf-b447-4b0a-b9f3-56f304d6fdde",
   "metadata": {},
   "source": [
    "# Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a786de7-43ac-4597-92eb-d9eee66f81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dir = os.path.join(output_base_dir,'holdout');\n",
    "output_dir = os.path.join(output_base_dir,'holdout_'+model_type);\n",
    "try: \n",
    "    os.mkdir(output_base_dir) \n",
    "except: \n",
    "    pass\n",
    "\n",
    "try: \n",
    "    os.mkdir(output_dir) \n",
    "except: \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf04e51-7a7b-4116-8e1e-04e5f358c5dc",
   "metadata": {},
   "source": [
    "# Create new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d629ba9-d621-4905-a88f-a0730d6c1802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 7)  532         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 256, 256, 7)  1232        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 256, 256, 7)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256, 256, 14  0           ['conv2d[0][0]',                 \n",
      "                                )                                 'leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 14  56         ['concatenate[0][0]']            \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 256, 256, 7)  2457        ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 256, 256, 7)  0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256, 256, 21  0           ['batch_normalization[0][0]',    \n",
      "                                )                                 'leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 256, 21  84         ['concatenate_1[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 21  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 128, 128, 7)  3682        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 128, 128, 7)  0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 28  0           ['max_pooling2d[0][0]',          \n",
      "                                )                                 'leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 28  112        ['concatenate_2[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 128, 128, 7)  4907        ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 128, 128, 7)  0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 128, 35  0           ['batch_normalization_2[0][0]',  \n",
      "                                )                                 'leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 35  140        ['concatenate_3[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 35)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 64, 7)    6132        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 64, 64, 7)    0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 64, 64, 42)   0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'leaky_re_lu_14[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 64, 42)  168         ['concatenate_4[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 64, 64, 7)    7357        ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 64, 64, 7)    0           ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 64, 64, 49)   0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'leaky_re_lu_17[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 49)  196         ['concatenate_5[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 49)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 32, 32, 7)    3094        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)     (None, 32, 32, 7)    0           ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 32, 32, 56)   0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'leaky_re_lu_20[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 56)  224         ['concatenate_6[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 32, 32, 7)    3535        ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_23 (LeakyReLU)     (None, 32, 32, 7)    0           ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 32, 32, 63)   0           ['batch_normalization_6[0][0]',  \n",
      "                                                                  'leaky_re_lu_23[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 63)  252         ['concatenate_7[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 16, 16, 63)  0           ['batch_normalization_7[0][0]']  \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 16, 16, 7)    3976        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_26 (LeakyReLU)     (None, 16, 16, 7)    0           ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 16, 16, 70)   0           ['average_pooling2d[0][0]',      \n",
      "                                                                  'leaky_re_lu_26[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 70)  280         ['concatenate_8[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 16, 16, 7)    4417        ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_29 (LeakyReLU)     (None, 16, 16, 7)    0           ['conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 16, 16, 77)   0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'leaky_re_lu_29[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 77)  308         ['concatenate_9[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 8, 8, 77)    0           ['batch_normalization_9[0][0]']  \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 8, 8, 7)      4858        ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " leaky_re_lu_32 (LeakyReLU)     (None, 8, 8, 7)      0           ['conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 8, 8, 84)     0           ['average_pooling2d_1[0][0]',    \n",
      "                                                                  'leaky_re_lu_32[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 8, 8, 84)    336         ['concatenate_10[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 8, 8, 7)      5299        ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " leaky_re_lu_35 (LeakyReLU)     (None, 8, 8, 7)      0           ['conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 8, 8, 91)     0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'leaky_re_lu_35[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 8, 8, 91)    364         ['concatenate_11[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 4, 4, 91)    0           ['batch_normalization_11[0][0]'] \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1456)         0           ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           23312       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 77,310\n",
      "Trainable params: 76,050\n",
      "Non-trainable params: 1,260\n",
      "__________________________________________________________________________________________________\n",
      "Loaded layer with custom_dense1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          (None, 16)                77310     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,085\n",
      "Trainable params: 76,825\n",
      "Non-trainable params: 1,260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import lib_model as mpp\n",
    "\n",
    "model, target_size = mpp.create_model('',model_type=model_type);\n",
    "model.summary()\n",
    "\n",
    "mpp.save_model_parameters(model, os.path.join(output_dir,'parameters_stats.m'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59917a-4069-439f-9108-e5b139498b01",
   "metadata": {},
   "source": [
    "# Defining directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac8f2152-96da-447d-b437-84f11e12937f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 504 validated image filenames belonging to 2 classes.\n",
      "Found 127 validated image filenames belonging to 2 classes.\n",
      "Found 273 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data_generator = idg.flow_from_dataframe(training_data, \n",
    "                                               directory = dataset_base_dir,\n",
    "                                               target_size=target_size,\n",
    "                                               x_col = \"filename\", \n",
    "                                               y_col = \"label\",\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               shuffle = True);\n",
    "\n",
    "valid_data_generator  = idg_val.flow_from_dataframe(validation_data, \n",
    "                                                    directory = dataset_base_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    x_col = \"filename\", \n",
    "                                                    y_col = \"label\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    shuffle = True);\n",
    "\n",
    "test_data_generator  = idg_test.flow_from_directory(dataset_base_test_dir, \n",
    "                                                    target_size=target_size,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True\n",
    "                                                    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1be572-b9c7-422c-9518-53735f9425c7",
   "metadata": {},
   "source": [
    "# Train and validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13cd68b8-e1aa-4ef4-af04-e05781f309ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/fernando/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 583, in start\n      self.io_loop.start()\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n      yield self.process_one()\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 250, in wrapper\n      runner = Runner(ctx_run, result, future, yielded)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 741, in __init__\n      self.ctx_run(self.run)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n      result = self._run_cell(\n    File \"/home/fernando/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n      return runner(coro)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/fernando/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/fernando/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-11-87abd4aec274>\", line 25, in <module>\n      history = model.fit(train_data_generator,\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/backend.py\", line 5134, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[32,7] labels_size=[32,2]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_4779]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-87abd4aec274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# This saves the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# FIT THE MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m history = model.fit(train_data_generator,\n\u001b[0m\u001b[1;32m     26\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_BY_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCAS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/fernando/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 583, in start\n      self.io_loop.start()\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n      yield self.process_one()\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 250, in wrapper\n      runner = Runner(ctx_run, result, future, yielded)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 741, in __init__\n      self.ctx_run(self.run)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/home/fernando/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n      result = self._run_cell(\n    File \"/home/fernando/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n      return runner(coro)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/fernando/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/fernando/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-11-87abd4aec274>\", line 25, in <module>\n      history = model.fit(train_data_generator,\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/home/fernando/.local/lib/python3.8/site-packages/keras/backend.py\", line 5134, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[32,7] labels_size=[32,2]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_4779]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "STEPS_BY_EPOCHS=len(train_data_generator);\n",
    "\n",
    "# COMPILE NEW MODEL\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "# CREATE CALLBACKS\n",
    "best_model_file=os.path.join(output_dir,'model.h5');\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=best_model_file, \n",
    "                                                save_weights_only=True,\n",
    "                                                monitor='val_categorical_accuracy', \n",
    "                                                save_best_only=True, \n",
    "                                                verbose=1);\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# There can be other callbacks, but just showing one because it involves the model name\n",
    "# This saves the best model\n",
    "# FIT THE MODEL\n",
    "history = model.fit(train_data_generator,\n",
    "                    steps_per_epoch=STEPS_BY_EPOCHS,\n",
    "                    epochs=EPOCAS,\n",
    "                    validation_data=valid_data_generator,\n",
    "                    callbacks=[checkpoint],\n",
    "                    verbose=1\n",
    "                   );\n",
    "\n",
    "\n",
    "mpp.save_model_history(history,os.path.join(output_dir,\"historical.csv\"));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083be078-c76e-423a-a538-6e5c6c9cda8c",
   "metadata": {},
   "source": [
    "# Evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f6536-46f0-4c89-b98f-7cb5a4075cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD BEST MODEL to evaluate the performance of the model\n",
    "model.load_weights(best_model_file);\n",
    "\n",
    "results = model.evaluate(test_data_generator)\n",
    "results = dict(zip(model.metrics_names,results))\n",
    "print(results,\"\\n\\n\");\n",
    "\n",
    "with open(os.path.join(output_dir,\"results_testing.txt\"), 'w') as f: \n",
    "    for key, value in results.items(): \n",
    "        f.write('%s=%s;\\n' % (key, value));\n",
    "\n",
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84facfa9-b65a-4fc8-85c7-025fd02f1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "POSTNAME=str(int(results['accuracy']*100000));\n",
    "\n",
    "tmp_name='modelo_'+model_type+'_acc'+POSTNAME+'.h5';\n",
    "\n",
    "os.rename(best_model_file,os.path.join(output_dir,tmp_name));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f70e376-46ee-40aa-bd19-1ea149d0a3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fecf1b-cef9-463b-b76d-ff614de2be37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
