{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a232a4-4048-4bc8-8611-e73e220894b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform, sys, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a866ec",
   "metadata": {},
   "source": [
    "# Install WorkingWithFiles\n",
    "To install WorkingWithFiles go to next link https://github.com/trucomanx/WorkingWithFiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cb04b2-e918-456e-989b-e3f8b5675ff8",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9a7e20-798f-4753-ae8e-b954d8af3942",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seed for the random variables\n",
    "seed_number=0;\n",
    "\n",
    "## Model of network\n",
    "model_type = 'mobilenet_v3';\n",
    "#model_type = 'efficientnet_b3'\n",
    "#model_type = 'inception_v3';\n",
    "#model_type = 'inception_resnet_v2';\n",
    "#model_type = 'resnet_v2_50';\n",
    "\n",
    "times=1;\n",
    "\n",
    "categories=['angry','disgusted','fearful','happy','neutral','sad','surprised'];\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0782e1",
   "metadata": {},
   "source": [
    "# Endere√ßos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf2d802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_base_dir: /mnt/boveda/DATASETs/FACE-EMOTION/fer2013/archive/test\n",
      "output_base_dir: /mnt/boveda/DOCTORADO2/cnn_face_emotion/test_custom\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Dataset \n",
    "if platform.system()=='Linux':\n",
    "    if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "        dataset_base_dir    = 'fer2013/archive/test';\n",
    "    elif 'microsoft-standard' in platform.uname().release:\n",
    "        dataset_base_dir    = '/mnt/c/Dados/Fernando/DATASET/fer2013/archive/test';\n",
    "    else:\n",
    "        dataset_base_dir    = '/mnt/boveda/DATASETs/FACE-EMOTION/fer2013/archive/test';\n",
    "else:\n",
    "    dataset_base_dir    = 'C:\\\\Dados\\\\Fernando\\\\DATASET\\\\fer2013\\\\archive\\\\test';\n",
    "\n",
    "print('dataset_base_dir:',dataset_base_dir)\n",
    "\n",
    "## Output\n",
    "if platform.system()=='Linux':\n",
    "    if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "        output_base_dir = 'OUTPUTS/cnn_face_emotion/test_custom';\n",
    "    elif 'microsoft-standard' in platform.uname().release:\n",
    "        output_base_dir = '/mnt/c/Dados/Fernando/OUTPUTS/cnn_face_emotion/test_custom';\n",
    "    else:\n",
    "        output_base_dir = '/mnt/boveda/DOCTORADO2/cnn_face_emotion/test_custom';\n",
    "else:\n",
    "    output_base_dir = 'C:\\\\Dados\\\\Fernando\\\\OUTPUTS\\\\cnn_face_emotion\\\\test_custom';\n",
    "\n",
    "print('output_base_dir:',output_base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c166a6",
   "metadata": {},
   "source": [
    "# Biblioteca Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11c8599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('library');\n",
    "import Classifier as mylib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4c5f1",
   "metadata": {},
   "source": [
    "# Bibliotecas externas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49cb967-206b-4a18-b1bb-d1779277e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import WorkingWithFiles as rnfunc\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e40561-74a1-4b75-aecf-14deeadb4d59",
   "metadata": {},
   "source": [
    "# If command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab4932ca-01af-43d5-a883-37be1bf0dbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_type: mobilenet_v3\n",
      "times: 1\n"
     ]
    }
   ],
   "source": [
    "#print('cmd entry:', sys.argv)\n",
    "\n",
    "for n in range(len(sys.argv)):\n",
    "    if sys.argv[n]=='--model':\n",
    "        model_type=sys.argv[n+1];\n",
    "    if sys.argv[n]=='--times':\n",
    "        times=int(sys.argv[n+1]);\n",
    "\n",
    "print('model_type:',model_type)\n",
    "print('times:',times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253521b5-8482-410e-ae33-3428e702f2b9",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5853861-85ff-49d6-93ed-30ede6066c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: mobilenet_v3\n",
      "Model mobilenet_v3 loaded.\n",
      "Loaded layer with mobilenet_v3\n"
     ]
    }
   ],
   "source": [
    "Clf=mylib.FaceEmotionClassifier(model_type);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b066f7-8739-4ba3-ba2a-14a9e5eae544",
   "metadata": {},
   "source": [
    "# Create directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "807c258d-5491-48c0-b01c-554ad7aec29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dir = os.path.join(output_base_dir,'holdout');\n",
    "output_dir = os.path.join(output_base_dir,'delay_'+model_type);\n",
    "\n",
    "try: \n",
    "    os.makedirs(output_dir) \n",
    "except: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd23a55-856a-4bc4-9c2e-3644ab3d0037",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3767f02-2397-465e-8307-ccf12f087832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytictoc import TicToc\n",
    "t = TicToc() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06bb382-0857-47c2-aa29-25f5e1c49c2f",
   "metadata": {},
   "source": [
    "# Testing people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06bd8881-fbdc-40d6-854b-3580de16eead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: angry\n",
      " Acc: angry : 0.6106471816283925\n",
      "Time: angry : 37.963171420000435\n",
      "category: disgusted\n",
      " Acc: disgusted : 0.6216216216216216\n",
      "Time: disgusted : 4.382489024001188\n",
      "category: fearful\n",
      " Acc: fearful : 0.4418377321603128\n",
      "Time: fearful : 40.792522636000285\n",
      "category: happy\n",
      " Acc: happy : 0.8776775648252536\n",
      "Time: happy : 71.25668668599974\n",
      "category: neutral\n",
      " Acc: neutral : 0.6063311688311688\n",
      "Time: neutral : 48.90729219499917\n",
      "category: sad\n",
      " Acc: sad : 0.5164658634538153\n",
      "Time: sad : 49.86975493099999\n",
      "category: surprised\n",
      " Acc: surprised : 0.8204819277108434\n",
      "Time: surprised : 32.56683067499944\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Ntot=0;\n",
    "Ltot=0;\n",
    "Ttot=0;\n",
    "for id in range(len(categories)):\n",
    "    category=categories[id];\n",
    "    \n",
    "    print('category:',category);\n",
    "    basedir=os.path.join(dataset_base_dir,category);\n",
    "    total_list=rnfunc.get_all_files_in_dir_list([basedir],formats_search=['.png']);\n",
    "\n",
    "    N0=0;\n",
    "    L0=len(total_list);\n",
    "\n",
    "    pil_image=[];\n",
    "    for n in range(L0):\n",
    "        pil_image.append(load_img(total_list[n]));\n",
    "\n",
    "    t.tic();\n",
    "    for m in range(times):\n",
    "        for n in range(L0):\n",
    "            res=Clf.is_pil_patient(pil_image[n]);\n",
    "            N0=N0+(res==id);\n",
    "    t0=t.tocvalue();\n",
    "\n",
    "    print(' Acc:',category,':',N0*1.0/(L0*times));\n",
    "    print('Time:',category,':',t0,'s');\n",
    "\n",
    "    Ntot=Ntot+N0*1.0/times;\n",
    "    Ltot=Ltot+L0;\n",
    "    Ttot=Ttot+t0*1.0/times;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17cfb89-593f-4d82-b001-289f924565fc",
   "metadata": {},
   "source": [
    "# Resultados finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "257d53cc-1f79-4c90-9614-f5d84e2e89fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.6599749058971142\n",
      "Delay 39.8353196106232 ms\n"
     ]
    }
   ],
   "source": [
    "acc=Ntot*1.0/Ltot;\n",
    "delayms=Ttot*1000.0/Ltot;\n",
    "\n",
    "print('Acc:',acc);\n",
    "print('Delay',delayms,'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f620ca3-6986-482b-96e9-650c08a757a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath=os.path.join(output_dir,\"times\"+str(times)+\"_acc_delayms.m\")\n",
    "\n",
    "fid = open(fpath, 'w')\n",
    "print('delayms={}'.format(delayms),';', file = fid);\n",
    "print('acc={}'.format(acc),';', file = fid);\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237afb0-89df-4882-8096-0c2bd21965f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
