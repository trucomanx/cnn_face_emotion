{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3410f40c-893b-449d-b024-7781e0d76733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ce46fc-8392-4e0b-a820-3ce426fcc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('library');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e27cb9-4b9a-4bec-bd30-d9b7a23ec5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0f452-3278-49c0-9601-c8a443dbc32b",
   "metadata": {},
   "source": [
    "# Variable globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83c3fa6-dbbb-4644-a12f-e497f971a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seed for the random variables\n",
    "seed_number=0;\n",
    "\n",
    "## Dataset \n",
    "dataset_base_dir    = '/mnt/boveda/DATASETs/FACE-EMOTION/fer2013/archive/train';\n",
    "dataset_labels_file = 'training_labels.csv';\n",
    "\n",
    "## Kfold \n",
    "K=5;                    # Variable K of kfold\n",
    "enable_stratified=True; # True: Stratified kfold False: Enable kfold \n",
    "\n",
    "## Training hyperparameters\n",
    "EPOCAS=50;\n",
    "BATCH_SIZE=32;#32\n",
    "\n",
    "## Model of network\n",
    "#model_type  = 'mobilenet_v3';\n",
    "#model_type = 'efficientnet_b3'\n",
    "#model_type = 'inception_v3';\n",
    "#model_type = 'inception_resnet_v2';\n",
    "#model_type = 'resnet_v2_50';\n",
    "#model_type = 'custom1'\n",
    "model_type = 'custom_inception'\n",
    "\n",
    "## Output\n",
    "output_base_dir = '/mnt/boveda/DOCTORADO2/cnn_face_emotion_free/cross-validation';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab5c325-9eda-4f6b-b4d8-99d2d433d896",
   "metadata": {},
   "source": [
    "# Parametros de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32302454-de63-4f6c-be9f-a72aac1643d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_type: custom_inception\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(sys.argv)):\n",
    "    if sys.argv[n]=='--model':\n",
    "        model_type=sys.argv[n+1];\n",
    "        \n",
    "print('model_type:',model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1dee5-778a-4fd9-80de-90620bb33128",
   "metadata": {},
   "source": [
    "# Set seed of random variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ddef12f-6604-4c71-9473-15f328e954dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "tf.keras.utils.set_random_seed(seed_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da712f-5937-4965-9623-82c4ee139297",
   "metadata": {},
   "source": [
    "# Setting the cross-validation kfold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcab2262-3467-4ee3-86a8-9eda4f5ff726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "if enable_stratified:\n",
    "    output_dir = os.path.join(output_base_dir,'skfold');\n",
    "    kf = StratifiedKFold(n_splits = K, shuffle = True, random_state = seed_number);\n",
    "else:\n",
    "    output_dir = os.path.join(output_base_dir,'kfold');\n",
    "    kf  = KFold(n_splits = K, shuffle=True, random_state=seed_number); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a59004-739e-4760-bd91-ee3808207e3e",
   "metadata": {},
   "source": [
    "# Loading data of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1abe0e9b-ee46-40d8-97c3-12a1efc0cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                filename      label\n",
      "0      disgusted/im0.png  disgusted\n",
      "1            sad/im0.png        sad\n",
      "2        fearful/im0.png    fearful\n",
      "3        neutral/im0.png    neutral\n",
      "4          angry/im0.png      angry\n",
      "...                  ...        ...\n",
      "28704   happy/im7210.png      happy\n",
      "28705   happy/im7211.png      happy\n",
      "28706   happy/im7212.png      happy\n",
      "28707   happy/im7213.png      happy\n",
      "28708   happy/im7214.png      happy\n",
      "\n",
      "[28709 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load filenames and labels\n",
    "train_data = pd.read_csv(os.path.join(dataset_base_dir,dataset_labels_file));\n",
    "print(train_data)\n",
    "# Setting labels\n",
    "Y   = train_data[['label']];\n",
    "L=np.shape(Y)[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67beeb38-1ad1-455d-8a71-5900a1e88163",
   "metadata": {},
   "source": [
    "# Data augmentation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e3e68f-50e7-4f8c-9cd6-ae3261e8f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "idg    = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range = 10,\n",
    "                            width_shift_range= 0.07,\n",
    "                            height_shift_range= 0.07,\n",
    "                            horizontal_flip=True,\n",
    "                            shear_range=1.25,\n",
    "                            zoom_range = [0.9, 1.1] \n",
    "                            )\n",
    "\n",
    "idg_val= ImageDataGenerator(rescale=1./255 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757c163-8553-4377-a387-a9cd3131ac04",
   "metadata": {},
   "source": [
    "# Auxiliar function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e6ca47-f504-47c5-99ad-db41692d40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5189cf-b447-4b0a-b9f3-56f304d6fdde",
   "metadata": {},
   "source": [
    "# Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a786de7-43ac-4597-92eb-d9eee66f81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try: \n",
    "    os.mkdir(output_dir) \n",
    "except: \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf04e51-7a7b-4116-8e1e-04e5f358c5dc",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd68b8-e1aa-4ef4-af04-e05781f309ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 1\n",
      "\n",
      "\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n",
      "                                                                 \n",
      " conv2d_94 (Conv2D)          (None, 8, 8, 16)          32784     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                32800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,868,368\n",
      "Trainable params: 65,584\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "Loaded layer with custom1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 32)                21868368  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,869,655\n",
      "Trainable params: 66,871\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "Found 22967 validated image filenames belonging to 7 classes.\n",
      "Found 5742 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.5640 - categorical_accuracy: 0.3889\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.44410, saving model to /mnt/boveda/DOCTORADO2/cnn_face_emotion_free/cross-validation/skfold/model_1.h5\n",
      "718/718 [==============================] - 2488s 3s/step - loss: 1.5640 - categorical_accuracy: 0.3889 - val_loss: 1.4352 - val_categorical_accuracy: 0.4441\n",
      "Epoch 2/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.4277 - categorical_accuracy: 0.4545\n",
      "Epoch 2: val_categorical_accuracy improved from 0.44410 to 0.47318, saving model to /mnt/boveda/DOCTORADO2/cnn_face_emotion_free/cross-validation/skfold/model_1.h5\n",
      "718/718 [==============================] - 2049s 3s/step - loss: 1.4277 - categorical_accuracy: 0.4545 - val_loss: 1.3734 - val_categorical_accuracy: 0.4732\n",
      "Epoch 3/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.3919 - categorical_accuracy: 0.4705\n",
      "Epoch 3: val_categorical_accuracy improved from 0.47318 to 0.48520, saving model to /mnt/boveda/DOCTORADO2/cnn_face_emotion_free/cross-validation/skfold/model_1.h5\n",
      "718/718 [==============================] - 2009s 3s/step - loss: 1.3919 - categorical_accuracy: 0.4705 - val_loss: 1.3399 - val_categorical_accuracy: 0.4852\n",
      "Epoch 4/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.3757 - categorical_accuracy: 0.4745\n",
      "Epoch 4: val_categorical_accuracy improved from 0.48520 to 0.48938, saving model to /mnt/boveda/DOCTORADO2/cnn_face_emotion_free/cross-validation/skfold/model_1.h5\n",
      "718/718 [==============================] - 2008s 3s/step - loss: 1.3757 - categorical_accuracy: 0.4745 - val_loss: 1.3356 - val_categorical_accuracy: 0.4894\n",
      "Epoch 5/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.3538 - categorical_accuracy: 0.4853\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.48938\n",
      "718/718 [==============================] - 2006s 3s/step - loss: 1.3538 - categorical_accuracy: 0.4853 - val_loss: 1.3418 - val_categorical_accuracy: 0.4854\n",
      "Epoch 6/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.3422 - categorical_accuracy: 0.4924\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.48938\n",
      "718/718 [==============================] - 2008s 3s/step - loss: 1.3422 - categorical_accuracy: 0.4924 - val_loss: 1.3418 - val_categorical_accuracy: 0.4885\n",
      "Epoch 7/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.3346 - categorical_accuracy: 0.4943\n",
      "Epoch 7: val_categorical_accuracy improved from 0.48938 to 0.49530, saving model to /mnt/boveda/DOCTORADO2/cnn_face_emotion_free/cross-validation/skfold/model_1.h5\n",
      "718/718 [==============================] - 2183s 3s/step - loss: 1.3346 - categorical_accuracy: 0.4943 - val_loss: 1.3297 - val_categorical_accuracy: 0.4953\n",
      "Epoch 8/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.3251 - categorical_accuracy: 0.4970\n",
      "Epoch 8: val_categorical_accuracy improved from 0.49530 to 0.50627, saving model to /mnt/boveda/DOCTORADO2/cnn_face_emotion_free/cross-validation/skfold/model_1.h5\n",
      "718/718 [==============================] - 2086s 3s/step - loss: 1.3251 - categorical_accuracy: 0.4970 - val_loss: 1.2985 - val_categorical_accuracy: 0.5063\n",
      "Epoch 9/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.3141 - categorical_accuracy: 0.5021\n",
      "Epoch 9: val_categorical_accuracy improved from 0.50627 to 0.51445, saving model to /mnt/boveda/DOCTORADO2/cnn_face_emotion_free/cross-validation/skfold/model_1.h5\n",
      "718/718 [==============================] - 2281s 3s/step - loss: 1.3141 - categorical_accuracy: 0.5021 - val_loss: 1.2972 - val_categorical_accuracy: 0.5145\n",
      "Epoch 10/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.3113 - categorical_accuracy: 0.5019\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.51445\n",
      "718/718 [==============================] - 2220s 3s/step - loss: 1.3113 - categorical_accuracy: 0.5019 - val_loss: 1.2807 - val_categorical_accuracy: 0.5117\n",
      "Epoch 11/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.3105 - categorical_accuracy: 0.5065\n",
      "Epoch 11: val_categorical_accuracy improved from 0.51445 to 0.51620, saving model to /mnt/boveda/DOCTORADO2/cnn_face_emotion_free/cross-validation/skfold/model_1.h5\n",
      "718/718 [==============================] - 2230s 3s/step - loss: 1.3105 - categorical_accuracy: 0.5065 - val_loss: 1.2757 - val_categorical_accuracy: 0.5162\n",
      "Epoch 12/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.3053 - categorical_accuracy: 0.5069\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.51620\n",
      "718/718 [==============================] - 2197s 3s/step - loss: 1.3053 - categorical_accuracy: 0.5069 - val_loss: 1.3357 - val_categorical_accuracy: 0.4842\n",
      "Epoch 13/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2992 - categorical_accuracy: 0.5068\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.51620\n",
      "718/718 [==============================] - 2277s 3s/step - loss: 1.2992 - categorical_accuracy: 0.5068 - val_loss: 1.2899 - val_categorical_accuracy: 0.5111\n",
      "Epoch 14/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2865 - categorical_accuracy: 0.5119\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.51620\n",
      "718/718 [==============================] - 2335s 3s/step - loss: 1.2865 - categorical_accuracy: 0.5119 - val_loss: 1.2860 - val_categorical_accuracy: 0.5104\n",
      "Epoch 15/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.3037 - categorical_accuracy: 0.5059\n",
      "Epoch 15: val_categorical_accuracy improved from 0.51620 to 0.51985, saving model to /mnt/boveda/DOCTORADO2/cnn_face_emotion_free/cross-validation/skfold/model_1.h5\n",
      "718/718 [==============================] - 2220s 3s/step - loss: 1.3037 - categorical_accuracy: 0.5059 - val_loss: 1.2734 - val_categorical_accuracy: 0.5199\n",
      "Epoch 16/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2921 - categorical_accuracy: 0.5075\n",
      "Epoch 16: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 2075s 3s/step - loss: 1.2921 - categorical_accuracy: 0.5075 - val_loss: 1.2798 - val_categorical_accuracy: 0.5122\n",
      "Epoch 17/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2944 - categorical_accuracy: 0.5147\n",
      "Epoch 17: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 1963s 3s/step - loss: 1.2944 - categorical_accuracy: 0.5147 - val_loss: 1.3078 - val_categorical_accuracy: 0.4969\n",
      "Epoch 18/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2918 - categorical_accuracy: 0.5118\n",
      "Epoch 18: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 1963s 3s/step - loss: 1.2918 - categorical_accuracy: 0.5118 - val_loss: 1.2895 - val_categorical_accuracy: 0.5188\n",
      "Epoch 19/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2851 - categorical_accuracy: 0.5157\n",
      "Epoch 19: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 1970s 3s/step - loss: 1.2851 - categorical_accuracy: 0.5157 - val_loss: 1.2768 - val_categorical_accuracy: 0.5115\n",
      "Epoch 20/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2799 - categorical_accuracy: 0.5194\n",
      "Epoch 20: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 1962s 3s/step - loss: 1.2799 - categorical_accuracy: 0.5194 - val_loss: 1.3028 - val_categorical_accuracy: 0.5098\n",
      "Epoch 21/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2792 - categorical_accuracy: 0.5144\n",
      "Epoch 21: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 1962s 3s/step - loss: 1.2792 - categorical_accuracy: 0.5144 - val_loss: 1.2956 - val_categorical_accuracy: 0.5131\n",
      "Epoch 22/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2796 - categorical_accuracy: 0.5146\n",
      "Epoch 22: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 1964s 3s/step - loss: 1.2796 - categorical_accuracy: 0.5146 - val_loss: 1.2709 - val_categorical_accuracy: 0.5186\n",
      "Epoch 23/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2761 - categorical_accuracy: 0.5177\n",
      "Epoch 23: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 1962s 3s/step - loss: 1.2761 - categorical_accuracy: 0.5177 - val_loss: 1.2920 - val_categorical_accuracy: 0.5131\n",
      "Epoch 24/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2819 - categorical_accuracy: 0.5133\n",
      "Epoch 24: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 1961s 3s/step - loss: 1.2819 - categorical_accuracy: 0.5133 - val_loss: 1.2680 - val_categorical_accuracy: 0.5193\n",
      "Epoch 25/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2831 - categorical_accuracy: 0.5179\n",
      "Epoch 25: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 1965s 3s/step - loss: 1.2831 - categorical_accuracy: 0.5179 - val_loss: 1.2849 - val_categorical_accuracy: 0.5118\n",
      "Epoch 26/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2643 - categorical_accuracy: 0.5241\n",
      "Epoch 26: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 1968s 3s/step - loss: 1.2643 - categorical_accuracy: 0.5241 - val_loss: 1.2812 - val_categorical_accuracy: 0.5176\n",
      "Epoch 27/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2702 - categorical_accuracy: 0.5227\n",
      "Epoch 27: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 1968s 3s/step - loss: 1.2702 - categorical_accuracy: 0.5227 - val_loss: 1.3010 - val_categorical_accuracy: 0.5016\n",
      "Epoch 28/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2715 - categorical_accuracy: 0.5178\n",
      "Epoch 28: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 2168s 3s/step - loss: 1.2715 - categorical_accuracy: 0.5178 - val_loss: 1.2674 - val_categorical_accuracy: 0.5158\n",
      "Epoch 29/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2767 - categorical_accuracy: 0.5144\n",
      "Epoch 29: val_categorical_accuracy did not improve from 0.51985\n",
      "718/718 [==============================] - 2229s 3s/step - loss: 1.2767 - categorical_accuracy: 0.5144 - val_loss: 1.2926 - val_categorical_accuracy: 0.5117\n",
      "Epoch 30/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.2811 - categorical_accuracy: 0.5166"
     ]
    }
   ],
   "source": [
    "import lib_model as mpp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "\n",
    "fold_var=1;\n",
    "for train_index, val_index in kf.split(np.zeros(L),Y):\n",
    "    training_data   = train_data.iloc[train_index]\n",
    "    validation_data = train_data.iloc[val_index]\n",
    "\n",
    "    print('\\nFold:',fold_var);\n",
    "    \n",
    "    # CREATE NEW MODEL\n",
    "    model, target_size = mpp.create_model('',model_type=model_type);\n",
    "    model.summary()\n",
    "    \n",
    "    train_data_generator = idg.flow_from_dataframe(training_data, \n",
    "                                                   directory = dataset_base_dir,\n",
    "                                                   target_size=target_size,\n",
    "                                                   x_col = \"filename\", \n",
    "                                                   y_col = \"label\",\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   shuffle = True);\n",
    "    \n",
    "    valid_data_generator  = idg_val.flow_from_dataframe(validation_data, \n",
    "                                                    directory = dataset_base_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    x_col = \"filename\", \n",
    "                                                    y_col = \"label\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    shuffle = True)\n",
    "    \n",
    "    STEPS_BY_EPOCHS=len(train_data_generator);\n",
    "    \n",
    "\n",
    "    \n",
    "    # COMPILE NEW MODEL\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    \n",
    "    # CREATE CALLBACKS\n",
    "    best_model_file=os.path.join(output_dir,get_model_name(fold_var));\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=best_model_file, \n",
    "                                                    save_weights_only=True,\n",
    "                                                    monitor='val_categorical_accuracy', \n",
    "                                                    save_best_only=True, \n",
    "                                                    verbose=1);\n",
    "    \n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    \n",
    "    # There can be other callbacks, but just showing one because it involves the model name\n",
    "    # This saves the best model\n",
    "    # FIT THE MODEL\n",
    "    history = model.fit(train_data_generator,\n",
    "                        steps_per_epoch=STEPS_BY_EPOCHS,\n",
    "                        epochs=EPOCAS,\n",
    "                        validation_data=valid_data_generator,\n",
    "                        callbacks=[checkpoint,tensorboard_callback],\n",
    "                        verbose=1\n",
    "                       );\n",
    "    \n",
    "    #PLOT HISTORY\n",
    "    mpp.save_model_history(history,os.path.join(output_dir,\"historical_\"+str(fold_var)+\".csv\"), labels=['categorical_accuracy','loss']);\n",
    "    \n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model.load_weights(best_model_file);\n",
    "    \n",
    "    results = model.evaluate(valid_data_generator)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "    print(results,\"\\n\\n\");\n",
    "    \n",
    "    VALIDATION_ACCURACY.append(results['categorical_accuracy'])\n",
    "    VALIDATION_LOSS.append(results['loss'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84facfa9-b65a-4fc8-85c7-025fd02f1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath=os.path.join(output_dir,\"final_stats.m\");\n",
    "mean_val_acc=mpp.save_model_stat_kfold(VALIDATION_ACCURACY,VALIDATION_LOSS, fpath);\n",
    "\n",
    "mpp.save_model_parameters(model, os.path.join(output_dir,'parameters_stats.m'));\n",
    "\n",
    "os.rename(output_dir,output_dir+str(K)+'_'+model_type+'_acc'+str(int(mean_val_acc*10000)));\n",
    "print(mean_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f70e376-46ee-40aa-bd19-1ea149d0a3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fecf1b-cef9-463b-b76d-ff614de2be37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
