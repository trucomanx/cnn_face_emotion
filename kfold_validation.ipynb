{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3410f40c-893b-449d-b024-7781e0d76733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ce46fc-8392-4e0b-a820-3ce426fcc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('library');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e27cb9-4b9a-4bec-bd30-d9b7a23ec5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0f452-3278-49c0-9601-c8a443dbc32b",
   "metadata": {},
   "source": [
    "# Variable globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83c3fa6-dbbb-4644-a12f-e497f971a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seed for the random variables\n",
    "seed_number=0;\n",
    "\n",
    "## Dataset \n",
    "dataset_base_dir    = '/mnt/boveda/DATASETs/FACE-EMOTION/fer2013/archive/train';\n",
    "dataset_labels_file = 'training_labels.csv';\n",
    "\n",
    "## Kfold \n",
    "K=5;                    # Variable K of kfold\n",
    "enable_stratified=True; # True: Stratified kfold False: Enable kfold \n",
    "\n",
    "## Training hyperparameters\n",
    "EPOCAS=50;\n",
    "BATCH_SIZE=32;#32\n",
    "\n",
    "## Model of network\n",
    "#model_type  = 'mobilenet_v3';\n",
    "#model_type = 'efficientnet_b3'\n",
    "#model_type = 'inception_v3';\n",
    "#model_type = 'inception_resnet_v2';\n",
    "#model_type = 'resnet_v2_50';\n",
    "#model_type = 'custom1'\n",
    "#model_type = 'custom_inception'\n",
    "#model_type = 'custom_residual1'\n",
    "model_type = 'custom_dense1'\n",
    "\n",
    "## Output\n",
    "output_base_dir = '/mnt/boveda/DOCTORADO2/cnn_face_emotion_free/cross-validation';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab5c325-9eda-4f6b-b4d8-99d2d433d896",
   "metadata": {},
   "source": [
    "# Parametros de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32302454-de63-4f6c-be9f-a72aac1643d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_type: custom_dense1\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(sys.argv)):\n",
    "    if sys.argv[n]=='--model':\n",
    "        model_type=sys.argv[n+1];\n",
    "        \n",
    "print('model_type:',model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1dee5-778a-4fd9-80de-90620bb33128",
   "metadata": {},
   "source": [
    "# Set seed of random variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ddef12f-6604-4c71-9473-15f328e954dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "tf.keras.utils.set_random_seed(seed_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da712f-5937-4965-9623-82c4ee139297",
   "metadata": {},
   "source": [
    "# Setting the cross-validation kfold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcab2262-3467-4ee3-86a8-9eda4f5ff726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "if enable_stratified:\n",
    "    output_dir = os.path.join(output_base_dir,'skfold');\n",
    "    kf = StratifiedKFold(n_splits = K, shuffle = True, random_state = seed_number);\n",
    "else:\n",
    "    output_dir = os.path.join(output_base_dir,'kfold');\n",
    "    kf  = KFold(n_splits = K, shuffle=True, random_state=seed_number); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a59004-739e-4760-bd91-ee3808207e3e",
   "metadata": {},
   "source": [
    "# Loading data of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1abe0e9b-ee46-40d8-97c3-12a1efc0cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                filename      label\n",
      "0      disgusted/im0.png  disgusted\n",
      "1            sad/im0.png        sad\n",
      "2        fearful/im0.png    fearful\n",
      "3        neutral/im0.png    neutral\n",
      "4          angry/im0.png      angry\n",
      "...                  ...        ...\n",
      "28704   happy/im7210.png      happy\n",
      "28705   happy/im7211.png      happy\n",
      "28706   happy/im7212.png      happy\n",
      "28707   happy/im7213.png      happy\n",
      "28708   happy/im7214.png      happy\n",
      "\n",
      "[28709 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load filenames and labels\n",
    "train_data = pd.read_csv(os.path.join(dataset_base_dir,dataset_labels_file));\n",
    "print(train_data)\n",
    "# Setting labels\n",
    "Y   = train_data[['label']];\n",
    "L=np.shape(Y)[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67beeb38-1ad1-455d-8a71-5900a1e88163",
   "metadata": {},
   "source": [
    "# Data augmentation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e3e68f-50e7-4f8c-9cd6-ae3261e8f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "idg    = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range = 10,\n",
    "                            width_shift_range= 0.07,\n",
    "                            height_shift_range= 0.07,\n",
    "                            horizontal_flip=True,\n",
    "                            shear_range=1.25,\n",
    "                            zoom_range = [0.9, 1.1] \n",
    "                            )\n",
    "\n",
    "idg_val= ImageDataGenerator(rescale=1./255 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757c163-8553-4377-a387-a9cd3131ac04",
   "metadata": {},
   "source": [
    "# Auxiliar function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e6ca47-f504-47c5-99ad-db41692d40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5189cf-b447-4b0a-b9f3-56f304d6fdde",
   "metadata": {},
   "source": [
    "# Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a786de7-43ac-4597-92eb-d9eee66f81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try: \n",
    "    os.mkdir(output_dir) \n",
    "except: \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf04e51-7a7b-4116-8e1e-04e5f358c5dc",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd68b8-e1aa-4ef4-af04-e05781f309ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 1\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 7)  532         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 256, 256, 7)  1232        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 256, 256, 7)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256, 256, 14  0           ['conv2d[0][0]',                 \n",
      "                                )                                 'leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 14  56         ['concatenate[0][0]']            \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 256, 256, 7)  2457        ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 256, 256, 7)  0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256, 256, 21  0           ['batch_normalization[0][0]',    \n",
      "                                )                                 'leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 256, 21  84         ['concatenate_1[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 21  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 128, 128, 7)  3682        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 128, 128, 7)  0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 28  0           ['max_pooling2d[0][0]',          \n",
      "                                )                                 'leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 28  112        ['concatenate_2[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 128, 128, 7)  4907        ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 128, 128, 7)  0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 128, 35  0           ['batch_normalization_2[0][0]',  \n",
      "                                )                                 'leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 35  140        ['concatenate_3[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 35)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 64, 7)    6132        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 64, 64, 7)    0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 64, 64, 42)   0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'leaky_re_lu_14[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 64, 42)  168         ['concatenate_4[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 64, 64, 7)    7357        ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 64, 64, 7)    0           ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 64, 64, 49)   0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'leaky_re_lu_17[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 49)  196         ['concatenate_5[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 49)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 32, 32, 7)    3094        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)     (None, 32, 32, 7)    0           ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 32, 32, 56)   0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'leaky_re_lu_20[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 56)  224         ['concatenate_6[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 32, 32, 7)    3535        ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_23 (LeakyReLU)     (None, 32, 32, 7)    0           ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 32, 32, 63)   0           ['batch_normalization_6[0][0]',  \n",
      "                                                                  'leaky_re_lu_23[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 63)  252         ['concatenate_7[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 63)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 16, 16, 7)    3976        ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_26 (LeakyReLU)     (None, 16, 16, 7)    0           ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 16, 16, 70)   0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'leaky_re_lu_26[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 70)  280         ['concatenate_8[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 16, 16, 7)    4417        ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_29 (LeakyReLU)     (None, 16, 16, 7)    0           ['conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 16, 16, 77)   0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'leaky_re_lu_29[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 77)  308         ['concatenate_9[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 77)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 8, 8, 7)      4858        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_32 (LeakyReLU)     (None, 8, 8, 7)      0           ['conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 8, 8, 84)     0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'leaky_re_lu_32[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 8, 8, 84)    336         ['concatenate_10[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 8, 8, 7)      5299        ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " leaky_re_lu_35 (LeakyReLU)     (None, 8, 8, 7)      0           ['conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 8, 8, 91)     0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'leaky_re_lu_35[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 8, 8, 91)    364         ['concatenate_11[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 91)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1456)         0           ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           23312       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 77,310\n",
      "Trainable params: 76,050\n",
      "Non-trainable params: 1,260\n",
      "__________________________________________________________________________________________________\n",
      "Loaded layer with custom_dense1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          (None, 16)                77310     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,085\n",
      "Trainable params: 76,825\n",
      "Non-trainable params: 1,260\n",
      "_________________________________________________________________\n",
      "Found 22967 validated image filenames belonging to 7 classes.\n",
      "Found 5742 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.7108 - categorical_accuracy: 0.3146\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.35841, saving model to /mnt/boveda/DOCTORADO2/cnn_face_emotion_free/cross-validation/skfold/model_1.h5\n",
      "718/718 [==============================] - 6002s 8s/step - loss: 1.7108 - categorical_accuracy: 0.3146 - val_loss: 1.6239 - val_categorical_accuracy: 0.3584\n",
      "Epoch 2/50\n",
      "248/718 [=========>....................] - ETA: 1:07:34 - loss: 1.5979 - categorical_accuracy: 0.3792"
     ]
    }
   ],
   "source": [
    "import lib_model as mpp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "\n",
    "fold_var=1;\n",
    "for train_index, val_index in kf.split(np.zeros(L),Y):\n",
    "    training_data   = train_data.iloc[train_index]\n",
    "    validation_data = train_data.iloc[val_index]\n",
    "\n",
    "    print('\\nFold:',fold_var);\n",
    "    \n",
    "    # CREATE NEW MODEL\n",
    "    model, target_size = mpp.create_model('',model_type=model_type);\n",
    "    model.summary()\n",
    "    \n",
    "    train_data_generator = idg.flow_from_dataframe(training_data, \n",
    "                                                   directory = dataset_base_dir,\n",
    "                                                   target_size=target_size,\n",
    "                                                   x_col = \"filename\", \n",
    "                                                   y_col = \"label\",\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   shuffle = True);\n",
    "    \n",
    "    valid_data_generator  = idg_val.flow_from_dataframe(validation_data, \n",
    "                                                    directory = dataset_base_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    x_col = \"filename\", \n",
    "                                                    y_col = \"label\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    shuffle = True)\n",
    "    \n",
    "    STEPS_BY_EPOCHS=len(train_data_generator);\n",
    "    \n",
    "\n",
    "    \n",
    "    # COMPILE NEW MODEL\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    \n",
    "    # CREATE CALLBACKS\n",
    "    best_model_file=os.path.join(output_dir,get_model_name(fold_var));\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=best_model_file, \n",
    "                                                    save_weights_only=True,\n",
    "                                                    monitor='val_categorical_accuracy', \n",
    "                                                    save_best_only=True, \n",
    "                                                    verbose=1);\n",
    "    \n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    \n",
    "    # There can be other callbacks, but just showing one because it involves the model name\n",
    "    # This saves the best model\n",
    "    # FIT THE MODEL\n",
    "    history = model.fit(train_data_generator,\n",
    "                        steps_per_epoch=STEPS_BY_EPOCHS,\n",
    "                        epochs=EPOCAS,\n",
    "                        validation_data=valid_data_generator,\n",
    "                        callbacks=[checkpoint,tensorboard_callback],\n",
    "                        verbose=1\n",
    "                       );\n",
    "    \n",
    "    #PLOT HISTORY\n",
    "    mpp.save_model_history(history,os.path.join(output_dir,\"historical_\"+str(fold_var)+\".csv\"), labels=['categorical_accuracy','loss']);\n",
    "    \n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model.load_weights(best_model_file);\n",
    "    \n",
    "    results = model.evaluate(valid_data_generator)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "    print(results,\"\\n\\n\");\n",
    "    \n",
    "    VALIDATION_ACCURACY.append(results['categorical_accuracy'])\n",
    "    VALIDATION_LOSS.append(results['loss'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84facfa9-b65a-4fc8-85c7-025fd02f1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath=os.path.join(output_dir,\"final_stats.m\");\n",
    "mean_val_acc=mpp.save_model_stat_kfold(VALIDATION_ACCURACY,VALIDATION_LOSS, fpath);\n",
    "\n",
    "mpp.save_model_parameters(model, os.path.join(output_dir,'parameters_stats.m'));\n",
    "\n",
    "os.rename(output_dir,output_dir+str(K)+'_'+model_type+'_acc'+str(int(mean_val_acc*10000)));\n",
    "print(mean_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f70e376-46ee-40aa-bd19-1ea149d0a3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fecf1b-cef9-463b-b76d-ff614de2be37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
